#![allow(unused)]

//! This module adds support for binary parsing of PGF binary files.
//!
//! This module implements a parser for the Portable Grammar Format (PGF) 
//! version 1.0, as specified in this document. It includes functionality for 
//! parsing PGF binary files, type checking, linearization, and JSON serialization. 
//! The code handles, among other things; correct version handling, full type 
//! and expression parsing, proper string length parsing, and support for 
//! equations, patterns, print names, and linearization definitions.
//! 
//! This first part of the module documentation is a reference for the exact 
//! format of PGF. The format described here is a version 1.0.
//!
//! The Haskell GF compiler can dump any PGF file into textual representation 
//! with a syntax close to what's used here. We can do so by using the following
//! command:
//!
//! > gf -make -output-format=pgf_pretty grammar_spec.pgf
//!
//! # Portal Grammar Format Specification | Version 1.0
//! 
//! ### Basic Types
//!
//! The Portable Grammar Format is a binary format where the structures of the
//! grammar are serialized as a sequence of bytes. Every structure is a list of
//! sequentially serialized fields, where every field is either another
//! structure or has a basic type. The allowed basic types are:
//!
//! - ﻿﻿Int8 - 8 bits integer, with sign, represented as a single byte.
//! - ﻿﻿Int16 - 16 bits integer, with sign, represented as a sequence of two
//! bytes where the most significant byte is stored first.
//! - ﻿﻿Int - a 32 bits integer with sign encoded as a sequence of bytes with
//! variable length. The last bit of every byte is an indication for whether
//! there are more bytes left. If the bit is 1, then there is at least one more
//! byte to be read, otherwise this is the last byte in the sequence.
//! The other 7 bits are parts of the stored integer. We store the bits from the
//!  least significant to the most significant.
//! - ﻿﻿String - a string in UTF-8 encoding. We first store as Int (a variable
//! length integer) the length of the string in number of Unicode characters and
//!  after that we add the UTF-8 encoding of the string itself.
//! - ﻿﻿Float - A double precision floating point number serialized in a
//! big-endian format following the IEEE754 standard.
//! - ﻿﻿List - Many of the object fields are lists of other objects.
//! We say that the field is of type [Object] if it contains a list of objects
//! of type Object. The list is serialized as a variable length integer
//! indicating the length of the list in number of objects, followed by the
//! serialization of the elements of the list.
//!
//! ---
//! ### PGF
//!
//! The whole PGF file contains only one structure which corresponds to the
//! abstract structure $G$ from Definition 1 in Section 2.1.
//! The structure has the following fields:
//!
//! | **type** | **description**                 |
//! | -------- | ------------------------------- |
//! | Int16    | major PGF version, should be 1. |
//! | Int16   | minor PGF version, should be 0. |
//! | [Flag]   | global flags                    |
//! | Abstract | abstract syntax                 |
//! | Concrete | list of concrete syntaxes       |
//! If PGF is changed in the future, the version in the first two fields should be updated.
//! The implementations can use the version number to maintain backward compatibility.
//!
//! ---
//! ### Flag
//!
//! The flags are pairs of a name and a literal and store different configuration parameters.
//! They are generated by the compiler and are accessible only internally from the interpreter.
//! By using flags we can add new settings without changing the format.
//!
//! | type    | description |
//! | ------- | ----------- |
//! | String  | flag name   |
//! | Literal | flag value  |
//!
//! ---
//! ### Abstract
//!
//! This is the object that represents the abstract syntax A (Definition 2, Section 2.1) 
//! of a grammar. The name of the abstract syntax is the name of the top-level 
//! abstract module in the grammar. The start category is specified with the flag startcat.
//!
//! | type     | description                     |
//! | -------- | ------------------------------- |
//! | String   | the name of the abstract syntax |
//! | [Flag]   | a list of flags                 |
//! | [AbsFun] | a list of abstract functions    |
//! | [AbsCat] | a list of abstract categories   |
//! Note: all lists are sorted by name which makes it easy to do binary search.
//!
//! ---
//! ### AbsFun
//!
//! Every abstract function is represented with one AbsFun object.
//!
//! | **type**   | **description**                                                     |
//! | ---------- | ------------------------------------------------------------------- |
//! | String     | the name of the function                                            |
//! | Type       | function's type signature                                           |
//! | Int        | function's arity                                                    |
//! | Int8       | a constructor tag: 0 - constructor; 1 - function                    |
//! | [Equation] | definitional equations for this function if it is not a constructor |
//! | Float      | the probability of the function                                     |
//! The constructor tag distinguishes between constructors and computable functions, i.e. we can distinguish between this two judgements:
//!
//! - ﻿﻿constructor: __data__ $f: T$
//! - ﻿﻿function: __fun__ $f: T$
//!
//! If this is a function, then we also include a list of definitional equations. The list can be empty which means that the function is an axiom. In the cases, when we have at least one equation then the arity is the number of arguments that have to be known in order to do pattern matching. For constructors or axioms the arity is zero.
//!
//! ---
//! ### AbsCat
//!
//! Every abstract category is represented with one AbsCat object. The object includes the name and the type information for the category plus a list of all functions whose return type is this category. The functions are listed in the order in which they appear in the source code.
//!
//! | type     | description                              |
//! | -------- | ---------------------------------------- |
//! | String   | the name of the category                 |
//! | [Hypo]   | a list of hypotheses                     |
//! | [CatFun] | a list of functions in source-code order |
//!
//! ---
//! ### CatFun
//!
//! This object is used internally to keep a list of abstract functions with their probabilities.
//!
//! | type   | description                     |
//! | ------ | ------------------------------- |
//! | String | the name of the function        |
//! | Float  | the probability of the function |
//!
//! ---
//! ### Type
//!
//! This is the description of an abstract syntax type. Since the types are monomorphic and in normal form, they have the general form:
//!
//! $$(X_1 : T_1) → (x_2 : T_2) → ... → (x_n: T_n) → C e_1... e_n$$
//!
//! The list of hypotheses $(x_i: T_i)$ is stored as a list of Hypo objects and the indices $e_1 ... e_n$ are stored as a list of expressions.
//!
//! | type         | description                                  |
//! | ------------ | -------------------------------------------- |
//! | [Hypo]       | a list of hypotheses                         |
//! | String       | the name of the category in the return type |
//! | [Expression] | indices in the return type                   |
//!
//! ---
//! ### Hypo
//!
//! Every Hypo object represents an argument in some function type. Since we support implicit and explicit arguments, the first field tells us whether we have explicit argument i.e. $(x: T)$ or implicit i.e. $(\{x\} : T)$. The next two fields are the name of the bound variable and its type. If no variable is bound then the name is $'_'$.
//!
//! | type     | description                                      |
//! | -------- | ------------------------------------------------ |
//! | BindType | the binding type i.e. implicit/explicit argument |
//! | String   | a variable name or $'_'$ if no variable is bound |
//! | Type     | the type of the variable                         |
//!
//! ---
//!
//! ### Equation
//!
//! Every computable function is represented with a list of equations where the equation is a pair of list of patterns and an expression. All equations must have the same number of patterns which is equal to the arity of the function.
//!
//! | type       | description              |
//! | ---------- | ------------------------ |
//! | [Pattern]  | a sequence of patterns   |
//! | Expression | an expression            |
//!
//! ---
//!
//! ### Pattern
//!
//! This is the representation of a single pattern in a definitional equation for computable function. The first field is a tag which encodes the kind of pattern.
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | a tag       |
//!
//! 1. ﻿﻿﻿tag=0 - pattern matching on constructor application (i.e. $c\; p_1 \;  p_2 ... p_n$)
//!
//! | type      | description                                 |
//! | --------- | ------------------------------------------- |
//! | String    | the name of the constructor                 |
//! | [Pattern] | a list of nested patterns for the arguments |
//!
//! 2. ﻿﻿﻿tag=1 - a variable type
//!
//! | type   | description       |
//! | ------ | ----------------- |
//! | String | the variable name |
//!
//! 3. ﻿﻿﻿tag=2 - a pattern which binds a variable but also does nested pattern matching (i.e. $x@p$) 
//!
//! | type    | description       |
//! | ------- | ----------------- |
//! | String  | the variable name |
//! | Pattern | a nested pattern  |
//!
//! 4. ﻿﻿﻿tag=3 - a wildcard (i.e. $_$).
//!
//! 5. ﻿﻿﻿tag=4 - matching a literal i.e. string, integer or float
//!
//! | type    | description              |
//! | ------- | ------------------------ |
//! | Literal | the value of the literal |
//!
//! 6. ﻿﻿﻿tag=5 - pattern matching on an implicit argument (i.e. $\{{P}\}$)
//!
//! | type      | description        |
//! | --------- | ------------------ |
//! | [Pattern] | the nested pattern |
//!
//! 7. tag=6 - an inaccessible pattern $(\sim p)$
//!
//! | type | description        |
//! | ---- | ------------------ |
//! | Expr | the nested pattern |
//!
//! ---
//!
//!
//!
//! ### Expression
//!
//! This is the encoding of an abstract syntax expression (tree).
//!
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | a tag       |
//!
//! 1. ﻿﻿﻿tag=0 - a lambda abstraction (i.e. $\\\x → ...$)
//!
//! | type       | description                          |
//! | ---------- | ------------------------------------ |
//! | BindType   | a tag for implicit/explicit argument |
//! | String     | the variable name                    |
//! | Expression | the body of the lambda abstraction   |
//!
//! 2. ﻿﻿﻿tag=1 - application (i.e. $f x$)
//!
//! | type       | description                        |
//! | ---------- | ---------------------------------- |
//! | Expression | the left-hand expression           |
//! | Expression | the right-hand expression          |
//! 3. ﻿﻿﻿tag=2 - a literal value i.e. string, integer or float type description
//!
//! | type    | description              |
//! | ------- | ------------------------ |
//! | Literal | the value of the literal |
//! 4. ﻿﻿﻿tag=3 - a metavariable (i.e. $?0, ?1,...$)
//!
//! | type | description                |
//! | ---- | -------------------------- |
//! | Int  | the id of the metavariable |
//!
//! 5. ﻿﻿﻿tag=4 - an abstract syntax function
//!
//! | type       | description                        |
//! | ---------- | ---------------------------------- |
//! | String     | the function name                  |
//!
//! 6. tag=5 - a variable
//!
//! | type | description                         |
//! | ---- | ----------------------------------- |
//! | Int  | the de Bruijn index of the variable |
//!
//! 7. tag=6 - an expression with a type annotation (i.e. $(e: t)$)
//!
//! | type       | description                |
//! | ---------- | -------------------------- |
//! | Expression | the annotated expression   |
//! | Type       | the type of the expression |
//!
//! 8. tag=7 - an implicit argument (i.e. $\{e\}$)
//!
//! | type       | description                     |
//! | ---------- | ------------------------------- |
//! | Expression | the expression for the argument |
//!
//! ---
//! ### Literal
//!
//! The Literal object represents the built-in kinds of literal constants. It starts with a tag which encodes the type of the constant:
//!
//! | type | description  |
//! | ---- | ------------ |
//! | Int8 | literal type |
//!
//! Currently we support only three types of literals:
//!
//! 1. ﻿﻿﻿tag=0 - string type
//!
//! | type   | description |
//! | ------ | ----------- |
//! | String | the value   |
//!
//!
//! 2. ﻿﻿﻿tag=1 - integer
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int  | the value   |
//!
//! 3. ﻿﻿﻿tag=2 - float type
//!
//! | type  | description |
//! | ----- | ----------- |
//! | Float | the value   |
//!
//! ---
//!
//!
//! ### BindType
//!
//! The bind type is a tag which encodes whether we have an explicit or an implicit argument.
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | tag         |
//!
//! ---
//!
//!
//! ### Concrete
//!
//! Every concrete syntax C (Definition 3, Section 2.1), in the grammar, is represented with an object. The name of the concrete syntax is the name of the top-level concrete module in the grammar.
//!
//! | type            | description                                                   |
//! | --------------- | ------------------------------------------------------------- |
//! | String          | the name of the concrete syntax                               |
//! | [Flag]          | a list of flags                                               |
//! | [PrintName]     | a list of print names                                         |
//! | [Sequence]      | a table with sequences (Section 2.8.1)                        |
//! | [CncFun]        | a list of concrete functions                                  |
//! | [LinDef]        | a list of functions for default linearization                 |
//! | [ProductionSet] | a list of production sets                                     |
//! | [CncCat]        | a list of concrete categories                                 |
//! | Int             | total number of concrete categories allocated for the grammar |
//! _Note:_ The lists Flag, PrintName and CncCat are sorted by name which makes it easy to do binary search.
//! _Note:_ The total number of concrete categories is used by the parser to determine whether a given category is part of the grammar, i.e. member of $N^C$, or it was created during the parsing. This is the way to decide when to put metavariables during the tree extraction (Section 2.3.7).
//!
//! ---
//! ### PrintName
//!
//! Every function or category can have a print name which is a user friendly name that can be displayed in the user interface instead of the real one. The print names are defined in the concrete syntax which makes it easier to localize the user interface to different languages.
//!
//! | type   | description                              |
//! | ------ | ---------------------------------------- |
//! | String | the name of the function or the category |
//! | String | the printable name                       |
//!
//! ---
//!
//! ### Sequence
//!
//! This is the representation of a single sequence in PMCFG, produced during the common subexpression optimization (Section 2.8.1).
//!
//! | type     | description       |
//! | -------- | ----------------- |
//! | [Symbol] | a list of symbols |
//!
//! ---
//!
//! ### Symbol
//!
//! The Symbol (Definition 4, Section 2.1) represents either a terminal or a function argument in some sequence. The representation starts with a tag encoding the type of the symbol:
//!
//! | type | description    |
//! | ---- | -------------- |
//! | Int8 | expression tag |
//!
//! The supported symbols are:
//!
//! 1. ﻿﻿﻿tag=0. This is the representation of an argument, i.e. a pair $\langle k; l \rangle$ ) where $k$ is the argument index and $l$ is the constituent index.
//!
//! | type | description       |
//! | ---- | ----------------- |
//! | Int  | argument index    |
//! | Int  | constituent index |
//!
//! 2. ﻿﻿﻿tag=1 This is again an argument but we use different tag to indicate that the target can be a literal category (see Section 2.6). If the target category is not a new fresh category, generated by the parser, then it is treated as a literal category. In the pgf_pretty format, we print this kind of symbols as $\{d; r\}$ instead of $\langle d; r  \rangle$ .
//!
//! | type | description       |
//! | ---- | ----------------- |
//! | Int  | argument index    |
//! | Int  | constituent index |
//!
//! 3. ﻿﻿﻿tag=2 A high-order argument i.e. $\langle d; \$r)$ (Section 2.7).
//!
//! | type | description     |
//! | ---- | --------------- |
//! | Int  | argument index  |
//! | Int  | variable number |
//!
//! 4.  ﻿﻿﻿tag=3 This is a terminal symbol and represents a list of tokens.
//!
//! | type     | description        |
//! | -------- | ------------------ |
//! | [String] | sequence of tokens |
//!
//! 5. ﻿﻿﻿tag=4 An alternative terminal symbol representing phrase, whose form depends on the prefix of the next token. It corresponds to the __pre__ construction in GF and encodes variations like a/an in English.
//!
//! | type          | description                |
//! | ------------- | -------------------------- |
//! | [String]      | the default form           |
//! | [Alternative] | a sequence of alternatives |
//!
//! ---
//!
//! ### Alternative
//!
//! Every Alternative represents one possible form of a phrase which is dependent on the prefix of the next token. For example when the construction:
//!
//! $$pre \{\text{"beau"}; \text{"bel"/"'ami"}\}$$
//!
//! is compiled then the alternative bel / ami will be represented by the pair (["bel"],[" ami"]).
//!
//! | type     | description                                  |
//! | -------- | -------------------------------------------- |
//! | [String] | The tokens to use if the prefix matches      |
//! | [String] | The prefix matched with the following tokens |
//!
//! ---
//! ### CncFun
//!
//! This is the definition of a single concrete function (Definition 4, Section
//! 2.1). The first field is the name of the corresponding abstract function
//! which gives us the direct definition of the $\psi_F$ mapping. The second
//! field is the function definition given as a list of indices pointing to the
//! sequences table (see the Concrete object).
//!
//! | type   | description                                     |
//! | ------ | ----------------------------------------------- |
//! | String | the name of the corresponding abstract function |
//! | [Int]  | list of indices into the sequences array        |
//!
//! ---
//!
//! ### LinDef
//!
//! The LinDef object stores the list of all concrete functions that can be used for the default linearization of some concrete category (Section 2.5).
//!
//! | type  | description                  |
//! | ----- | ---------------------------- |
//! | Int   | the concrete category        |
//! | [Int] | a list of concrete functions |
//!
//! ---
//!
//! ### ProductionSet
//!
//! A group of productions with the same result category. The productions are grouped because this makes it easier for the parser to find the relevant productions in the prediction step:
//!
//! | type         | description           |
//! | ------------ | --------------------- |
//! | Int          | the result category   |
//! | [Production] | a list of productions |
//!
//! ---
//!
//! ### Production
//!
//! The production can be either an application of some function or a coercion.
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | tag         |
//! 1. tag=0 the production is an application (Definition 4, Section 2.1):
//!
//! | type   | description           |
//! | ------ | --------------------- |
//! | Int    | the concrete function |
//! | [PArg] | a list of arguments   |
//!
//! 2. tag=1 the production is a coercion (Section 2.8.1):
//!
//! | type | description         |
//! | ---- | ------------------- |
//! | Int8 | a concrete category |
//!
//! ---
//! ### PArg
//!
//! An argument in a production.
//!
//! | type  | description                                              |
//! | ----- | -------------------------------------------------------- |
//! | [Int] | the categories of the high-order arguments (Section 2.7) |
//! | Int   | a concrete category                                      |
//!
//! ---
//!
//! ### CncCat
//!
//! This is the representation of a set of concrete categories which map to the
//! same abstract category. Since all concrete categories generated from the
//! same abstract category are always represented as consecutive integers, here
//! we store only the first and the last category. The compiler also generates
//! a name for every constituent so here we have the list of names. The length
//! of the list is equal to the dimension of the category.
//!
//! | type     | description                                                   |
//! | -------- | ------------------------------------------------------------- |
//! | String   | the name of the corresponding (by $\psi_N$) abstract category |
//! | Int      | the first concrete category                                   |
//! | Int      | the last concrete category                                    |
//! | [String] | a list of constituent names

use std::collections::HashMap;
use std::fs::File;
use std::io::{self, Cursor, Read};
use bytes::Bytes;
use serde::{Deserialize, Serialize};
use serde_json::{json, Value as JsonValue};
use thiserror::Error;
use byteorder::{BigEndian, ReadBytesExt};

// Errors that can occur during PGF operations.
#[derive(Error, Debug)]
pub enum PgfError {
    #[error("IO error: {0}")]
    Io(#[from] io::Error),
    #[error("Unknown language: {0}")]
    UnknownLanguage(String),
    #[error("Deserialization error at offset {offset}: {message}")]
    DeserializeError { offset: u64, message: String },
    #[error("Serialization error: {0}")]
    SerializeError(String),
    #[error("Type checking error: {0}")]
    TypeCheckError(String),
    #[error("Parsing error: {0}")]
    ParseError(String),
}

// Represents a Portable Grammar Format (PGF) structure.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Pgf {
    absname: CId,
    concretes: HashMap<Language, Concrete>,
    r#abstract: Abstract,
    startcat: CId,
    flags: HashMap<CId, Literal>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Abstract {
    funs: HashMap<CId, Function>,
    cats: HashMap<CId, Category>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Concrete {
    cflags: HashMap<CId, Literal>,
    productions: HashMap<i32, Vec<Production>>, // Changed to Vec for efficiency
    cncfuns: Vec<CncFun>,
    sequences: Vec<Vec<Symbol>>,
    cnccats: HashMap<CId, CncCat>,
    printnames: Vec<PrintName>,
    lindefs: Vec<LinDef>,
    total_cats: i32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Function {
    ty: Type,
    weight: i32,
    equations: Option<Vec<Equation>>,
    arity: i32,
    is_constructor: bool,
    prob: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Category {
    hypos: Vec<Hypo>,
    funs: Vec<(usize, CId)>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct CId(String);

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Language(CId);

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Hypo {
    binding: Binding,
    ty: Type,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Binding {
    Explicit(String),
    Implicit(String),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Type {
    hypos: Vec<Hypo>,
    category: CId,
    exprs: Vec<Expr>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Literal {
    Str(String),
    Int(i32),
    Flt(f64),
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct CncCat {
    name: CId,
    start: i32,
    end: i32,
    labels: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct CncFun {
    name: CId,
    lins: Vec<i32>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum Production {
    Apply { fid: i32, args: Vec<PArg> },
    Coerce { arg: i32 },
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct PArg {
    hypos: Vec<i32>,
    fid: i32,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct PrintName {
    name: CId,
    printname: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct LinDef {
    cat: i32,
    funs: Vec<i32>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum Symbol {
    SymCat(i32, i32),
    SymLit(i32, i32),
    SymVar(i32, i32),
    SymKS(String),
    SymKP(Vec<String>, Vec<Alt>),
    SymNE,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct Alt {
    tokens: Vec<String>,
    prefixes: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Equation {
    patterns: Vec<Pattern>,
    result: Expr,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Pattern {
    PApp(CId, Vec<Pattern>),
    PVar(CId),
    PBind(CId, Box<Pattern>),
    PWildcard,
    PLit(Literal),
    PImplicit(Vec<Pattern>),
    PInaccessible(Expr),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Expr {
    Abs(Binding, CId, Box<Expr>),
    App(Box<Expr>, Box<Expr>),
    Fun(CId),
    Str(String),
    Int(i32),
    Float(f32),
    Double(f64),
    Meta(i32),
    Typed(Box<Expr>, Type),
    ImplArg(Box<Expr>),
    Lit(Literal),
    Var(i32),
}

pub mod cid {
    use super::CId;

    pub fn mk_cid(s: &str) -> CId {
        CId(s.to_string())
    }

    pub fn wild_cid() -> CId {
        CId("*".to_string())
    }

    pub fn show_cid(cid: &CId) -> String {
        cid.0.clone()
    }

    pub fn read_cid(s: &str) -> Option<CId> {
        if s.is_empty() {
            None
        } else {
            Some(CId(s.to_string()))
        }
    }
}

pub mod language {
    use super::{CId, Language, Pgf, Literal};

    pub fn show_language(lang: &Language) -> String {
        super::cid::show_cid(&lang.0)
    }

    pub fn read_language(s: &str) -> Option<Language> {
        super::cid::read_cid(s).map(Language)
    }

    pub fn languages(pgf: &Pgf) -> Vec<Language> {
        pgf.concretes.keys().cloned().collect()
    }

    pub fn language_code(pgf: &Pgf, lang: &Language) -> Option<String> {
        pgf.concretes.get(lang).and_then(|cnc| {
            cnc.cflags.get(&CId("language".to_string())).and_then(|lit| {
                match lit {
                    Literal::Str(s) => Some(s.replace('_', "-")),
                    _ => None,
                }
            })
        })
    }

    pub fn abstract_name(pgf: &Pgf) -> Language {
        Language(pgf.absname.clone())
    }
}

pub mod types {
    use super::{CId, Hypo, Type, Pgf};

    pub fn mk_type(hypos: Vec<Hypo>, cat: CId, exprs: Vec<super::Expr>) -> Type {
        Type {
            hypos,
            category: cat,
            exprs,
        }
    }

    pub fn mk_hypo(binding: super::Binding, ty: Type) -> Hypo {
        Hypo { binding, ty }
    }

    pub fn start_cat(pgf: &Pgf) -> Type {
        Type {
            hypos: vec![],
            category: pgf.startcat.clone(),
            exprs: vec![],
        }
    }
}

pub mod parse {
    use super::{Pgf, Language, Type, Expr, Production, Symbol, PgfError, CncFun, BracketedString, cid};
    use std::collections::HashMap;

    #[derive(Debug, Clone)]
    pub struct ParseState {
        pgf: Pgf,
        lang: Language,
        typ: Type,
        active_items: HashMap<i32, Vec<Item>>,
        passive_items: HashMap<i32, Vec<Item>>,
        tokens: Vec<String>,
        current_pos: usize,
    }

    #[derive(Debug, Clone)]
    pub struct Item {
        fid: i32,
        seqid: i32,
        dot: usize,
        args: Vec<(i32, Expr)>,
        tree: Option<Expr>,
    }

    #[derive(Debug, Clone)]
    pub struct ParseInput {
        pub token: String,
    }

    #[derive(Debug, Clone)]
    pub enum ParseOutput {
        ParseOk(Vec<Expr>),
        ParseFail,
    }

    pub fn init_state(pgf: &Pgf, lang: &Language, typ: &Type) -> Result<ParseState, PgfError> {
        let cnc = pgf.concretes.get(lang).ok_or_else(|| PgfError::UnknownLanguage(cid::show_cid(&lang.0)))?;
        let cat_id = cnc.cnccats.get(&typ.category)
            .map(|cat| cat.start)
            .ok_or_else(|| PgfError::ParseError(format!("Category not found: {}", cid::show_cid(&typ.category))))?;
        let mut active_items = HashMap::new();
        if let Some(prods) = cnc.productions.get(&cat_id) {
            for prod in prods {
                if let Production::Apply { fid, args: _ } = prod {
                    let item = Item {
                        fid: *fid,
                        seqid: cnc.cncfuns.get(*fid as usize).map(|f| f.lins.get(0).copied().unwrap_or(0)).unwrap_or(0),
                        dot: 0,
                        args: vec![],
                        tree: None,
                    };
                    active_items.entry(cat_id).or_insert_with(Vec::new).push(item);
                }
            }
        }
        Ok(ParseState {
            pgf: pgf.clone(),
            lang: lang.clone(),
            typ: typ.clone(),
            active_items,
            passive_items: HashMap::new(),
            tokens: vec![],
            current_pos: 0,
        })
    }

    pub fn next_state(state: &mut ParseState, input: ParseInput) -> Result<(), PgfError> {
        state.tokens.push(input.token.clone());
        let cnc = state.pgf.concretes.get(&state.lang)
            .ok_or_else(|| PgfError::ParseError("Language not found".to_string()))?;

        let mut new_active = HashMap::new();
        let mut new_passive = state.passive_items.clone();

        for (cat_id, items) in state.active_items.iter() {
            for item in items {
                if let Some(seq) = cnc.sequences.get(item.seqid as usize) {
                    if item.dot < seq.len() {
                        match &seq[item.dot] {
                            Symbol::SymKS(token) => {
                                if token == &input.token {
                                    let new_item = Item {
                                        dot: item.dot + 1,
                                        ..item.clone()
                                    };
                                    new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                                }
                            }
                            Symbol::SymKP(tokens, alts) => {
                                let matches = tokens.iter().any(|t| t == &input.token) ||
                                    alts.iter().any(|alt| alt.tokens.iter().any(|t| t == &input.token) &&
                                        alt.prefixes.iter().any(|p| input.token.starts_with(p)));
                                if matches {
                                    let new_item = Item {
                                        dot: item.dot + 1,
                                        ..item.clone()
                                    };
                                    new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                                }
                            }
                            Symbol::SymCat(_, next_fid) | Symbol::SymLit(_, next_fid) => {
                                if let Some(passive) = new_passive.get(next_fid) {
                                    for pitem in passive {
                                        if let Some(tree) = &pitem.tree {
                                            let mut new_args = item.args.clone();
                                            new_args.push((*next_fid, tree.clone()));
                                            let new_item = Item {
                                                dot: item.dot + 1,
                                                args: new_args,
                                                ..item.clone()
                                            };
                                            new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                                        }
                                    }
                                }
                            }
                            Symbol::SymVar(_, next_fid) => {
                                // Handle variable symbols (e.g., high-order arguments)
                                let new_item = Item {
                                    dot: item.dot + 1,
                                    ..item.clone()
                                };
                                new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                            }
                            Symbol::SymNE => {
                                // Handle empty symbol (if applicable)
                                let new_item = Item {
                                    dot: item.dot + 1,
                                    ..item.clone()
                                };
                                new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                            }
                        }
                    } else {
                        let tree = build_tree(&cnc.cncfuns[item.fid as usize], &item.args);
                        let passive_item = Item {
                            tree: Some(tree),
                            ..item.clone()
                        };
                        new_passive.entry(*cat_id).or_insert_with(Vec::new).push(passive_item);
                    }
                }
            }
        }

        for (cat_id, prods) in cnc.productions.iter() {
            for prod in prods {
                if let Production::Coerce { arg } = prod {
                    if let Some(passive) = new_passive.get(arg) {
                        for pitem in passive {
                            if let Some(tree) = &pitem.tree {
                                let new_item = Item {
                                    fid: *cat_id,
                                    seqid: 0,
                                    dot: 0,
                                    args: vec![(*arg, tree.clone())],
                                    tree: None,
                                };
                                new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                            }
                        }
                    }
                }
            }
        }

        state.active_items = new_active;
        state.passive_items = new_passive;
        state.current_pos += 1;
        Ok(())
    }

    fn build_tree(cnc_fun: &CncFun, args: &[(i32, Expr)]) -> Expr {
        let mut tree = Expr::Fun(cnc_fun.name.clone());
        for (_, arg) in args {
            tree = Expr::App(Box::new(tree), Box::new(arg.clone()));
        }
        tree
    }

    pub fn get_parse_output(state: &ParseState, typ: &Type, depth: Option<i32>) -> (ParseOutput, BracketedString) {
        let max_depth = depth.unwrap_or(i32::MAX);
        let cnc = state.pgf.concretes.get(&state.lang).expect("Language not found");
        let cat_id = cnc.cnccats.get(&typ.category).map(|cat| cat.start).unwrap_or(0);

        let mut trees = vec![];
        if let Some(items) = state.passive_items.get(&cat_id) {
            for item in items {
                if let Some(tree) = &item.tree {
                    if item.dot == cnc.sequences.get(item.seqid as usize).map_or(0, |seq| seq.len()) {
                        trees.push(tree.clone());
                    }
                }
            }
        }

        let bracketed = if trees.is_empty() {
            BracketedString::Leaf("".to_string())
        } else {
            BracketedString::Branch(typ.category.clone(), trees.iter().map(|t| expr_to_bracketed(t)).collect())
        };

        if trees.is_empty() {
            (ParseOutput::ParseFail, bracketed)
        } else {
            (ParseOutput::ParseOk(trees), bracketed)
        }
    }

    fn expr_to_bracketed(expr: &Expr) -> BracketedString {
        match expr {
            Expr::Fun(cid) => BracketedString::Leaf(cid::show_cid(cid)),
            Expr::App(e1, e2) => {
                let mut children = vec![expr_to_bracketed(e1)];
                children.push(expr_to_bracketed(e2));
                BracketedString::Branch(cid::wild_cid(), children)
            }
            _ => BracketedString::Leaf("".to_string()),
        }
    }
}

#[derive(Debug, Clone)]
pub enum BracketedString {
    Leaf(String),
    Branch(CId, Vec<BracketedString>),
}

pub fn read_pgf(path: &str) -> Result<Pgf, PgfError> {
    let mut file = File::open(path)?;
    let mut bytes = Vec::new();
    file.read_to_end(&mut bytes)?;
    parse_pgf(Bytes::from(bytes))
}

pub fn parse_pgf(data: Bytes) -> Result<Pgf, PgfError> {
    let mut cursor = Cursor::new(&data[..]);
    parse_pgf_binary(&mut cursor)
}

fn parse_pgf_binary(cursor: &mut Cursor<&[u8]>) -> Result<Pgf, PgfError> {
    let offset = cursor.position();
    let major_version = cursor.read_i16::<BigEndian>()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read major version: {}", e) })?;
    let minor_version = cursor.read_i16::<BigEndian>()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read minor version: {}", e) })?;

    if major_version < 1 || major_version > 2 {
        return Err(PgfError::DeserializeError {
            offset,
            message: format!("Unsupported PGF version: {}.{}", major_version, minor_version),
        });
    }

    let flags = read_flags(cursor)?;
    let r#abstract = read_abstract(cursor)?;
    let concretes = read_concretes(cursor)?;

    let startcat = flags.get(&cid::mk_cid("startcat"))
        .and_then(|lit| match lit {
            Literal::Str(s) => Some(cid::mk_cid(s)),
            _ => None,
        })
        .unwrap_or_else(|| r#abstract.cats.keys().next().cloned().unwrap_or(cid::mk_cid("S")));

    let absname = r#abstract.funs.keys().next().map_or(cid::mk_cid("Abstract"), |f| f.clone());

    Ok(Pgf {
        absname,
        concretes,
        r#abstract,
        startcat,
        flags,
    })
}

fn read_flags(cursor: &mut Cursor<&[u8]>) -> Result<HashMap<CId, Literal>, PgfError> {
    let offset = cursor.position();
    let count = read_int(cursor)?;
    let mut flags = HashMap::new();
    for _ in 0..count {
        let key = read_string(cursor)?;
        let value = read_literal(cursor)?;
        flags.insert(key, value);
    }
    Ok(flags)
}

fn read_int(cursor: &mut Cursor<&[u8]>) -> Result<i32, PgfError> {
    let offset = cursor.position();
    let mut result: u32 = 0;
    let mut shift = 0;
    loop {
        let byte = cursor.read_u8()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read int byte: {}", e) })?;
        let val = (byte & 0x7F) as u32;
        result |= val << shift;
        shift += 7;
        if byte & 0x80 == 0 {
            break;
        }
    }
    Ok(result as i32)
}

fn read_literal(cursor: &mut Cursor<&[u8]>) -> Result<Literal, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read literal tag: {}", e) })?;
    match tag {
        0 => Ok(Literal::Str(read_string(cursor)?.0)),
        1 => Ok(Literal::Int(read_int(cursor)?)),
        2 => Ok(Literal::Flt(cursor.read_f64::<BigEndian>()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read float: {}", e) })?)),
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown literal tag: {}", tag) }),
    }
}


fn read_string(cursor: &mut Cursor<&[u8]>) -> Result<CId, PgfError> {
    let offset = cursor.position();
    let len = read_int(cursor)? as usize;
    let mut buf = vec![0u8; len];
    cursor.read_exact(&mut buf)
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read string: {}", e) })?;
    let s = String::from_utf8(buf)
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Invalid UTF-8 string: {}", e) })?;
    Ok(cid::mk_cid(&s))
}

fn read_abstract(cursor: &mut Cursor<&[u8]>) -> Result<Abstract, PgfError> {
    let offset = cursor.position();
    let name = read_string(cursor)?;
    let flags = read_flags(cursor)?;
    let fun_count = read_int(cursor)?;
    let mut funs = HashMap::new();
    let mut cats = HashMap::new();

    for _ in 0..fun_count {
        let fun_name = read_string(cursor)?;
        let ty = read_type(cursor, 0)?;
        let arity = read_int(cursor)?;
        let tag = cursor.read_u8()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read function tag: {}", e) })?;
        let is_constructor = tag == 0;
        let equations = if tag == 1 {
            Some(read_list(cursor, read_equation)?)
        } else {
            None
        };
        let prob = cursor.read_f64::<BigEndian>()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read probability: {}", e) })?;

        funs.insert(fun_name.clone(), Function {
            ty: ty.clone(),
            weight: 1, // Default weight
            equations,
            arity,
            is_constructor,
            prob,
        });

        cats.entry(ty.category.clone())
            .or_insert_with(|| Category { hypos: vec![], funs: vec![] })
            .funs.push((0, fun_name));
    }

    let cat_count = read_int(cursor)?;
    for _ in 0..cat_count {
        let cat_name = read_string(cursor)?;
        let hypos = read_list(cursor, read_hypo)?;
        let cat_funs = read_list(cursor, |cursor| {
            let name = read_string(cursor)?;
            let prob = cursor.read_f64::<BigEndian>()
                .map_err(|e| PgfError::DeserializeError { offset: cursor.position(), message: format!("Failed to read cat fun prob: {}", e) })?;
            Ok((0, name))
        })?;
        cats.insert(cat_name, Category { hypos, funs: cat_funs });
    }

    Ok(Abstract { funs, cats })
}

fn read_type(cursor: &mut Cursor<&[u8]>, depth: u32) -> Result<Type, PgfError> {
    const MAX_DEPTH: u32 = 100;
    if depth > MAX_DEPTH {
        return Err(PgfError::DeserializeError {
            offset: cursor.position(),
            message: "Maximum recursion depth exceeded in type parsing".to_string(),
        });
    }
    let offset = cursor.position();
    let hypos = read_list(cursor, |c| read_hypo(c))?;
    let category = read_string(cursor)?;
    let exprs = read_list(cursor, |c| read_expr(c, depth + 1))?;
    Ok(Type { hypos, category, exprs })
}

fn read_hypo(cursor: &mut Cursor<&[u8]>) -> Result<Hypo, PgfError> {
    let offset = cursor.position();
    let binding = read_binding(cursor)?;
    let ty = read_type(cursor, 0)?;
    Ok(Hypo { binding, ty })
}

fn read_binding(cursor: &mut Cursor<&[u8]>) -> Result<Binding, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read binding tag: {}", e) })?;
    let name = read_string(cursor)?;
    match tag {
        0 => Ok(Binding::Explicit(cid::show_cid(&name))),
        1 => Ok(Binding::Implicit(cid::show_cid(&name))),
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown binding tag: {}", tag) }),
    }
}

fn read_expr(cursor: &mut Cursor<&[u8]>, depth: u32) -> Result<Expr, PgfError> {
    const MAX_DEPTH: u32 = 100;
    if depth > MAX_DEPTH {
        return Err(PgfError::DeserializeError {
            offset: cursor.position(),
            message: "Maximum recursion depth exceeded in expression parsing".to_string(),
        });
    }
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read expr tag: {}", e) })?;
    match tag {
        0 => {
            let binding = read_binding(cursor)?;
            let var = read_string(cursor)?;
            let body = read_expr(cursor, depth + 1)?;
            Ok(Expr::Abs(binding, var, Box::new(body)))
        }
        1 => {
            let lhs = read_expr(cursor, depth + 1)?;
            let rhs = read_expr(cursor, depth + 1)?;
            Ok(Expr::App(Box::new(lhs), Box::new(rhs)))
        }
        2 => Ok(Expr::Lit(read_literal(cursor)?)),
        3 => Ok(Expr::Meta(read_int(cursor)?)),
        4 => Ok(Expr::Fun(read_string(cursor)?)),
        5 => Ok(Expr::Var(read_int(cursor)?)),
        6 => {
            let expr = read_expr(cursor, depth + 1)?;
            let ty = read_type(cursor, depth + 1)?;
            Ok(Expr::Typed(Box::new(expr), ty))
        }
        7 => {
            let expr = read_expr(cursor, depth + 1)?;
            Ok(Expr::ImplArg(Box::new(expr)))
        }
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown expr tag: {}", tag) }),
    }
}

fn read_equation(cursor: &mut Cursor<&[u8]>) -> Result<Equation, PgfError> {
    let patterns = read_list(cursor, read_pattern)?;
    let result = read_expr(cursor, 0)?;
    Ok(Equation { patterns, result })
}

fn read_pattern(cursor: &mut Cursor<&[u8]>) -> Result<Pattern, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read pattern tag: {}", e) })?;
    match tag {
        0 => {
            let constr = read_string(cursor)?;
            let patterns = read_list(cursor, read_pattern)?;
            Ok(Pattern::PApp(constr, patterns))
        }
        1 => Ok(Pattern::PVar(read_string(cursor)?)),
        2 => {
            let var = read_string(cursor)?;
            let pattern = read_pattern(cursor)?;
            Ok(Pattern::PBind(var, Box::new(pattern)))
        }
        3 => Ok(Pattern::PWildcard),
        4 => Ok(Pattern::PLit(read_literal(cursor)?)),
        5 => Ok(Pattern::PImplicit(read_list(cursor, read_pattern)?)),
        6 => Ok(Pattern::PInaccessible(read_expr(cursor, 0)?)),
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown pattern tag: {}", tag) }),
    }
}

fn read_concretes(cursor: &mut Cursor<&[u8]>) -> Result<HashMap<Language, Concrete>, PgfError> {
    let offset = cursor.position();
    let count = read_int(cursor)?;
    let mut concretes = HashMap::new();
    for _ in 0..count {
        let lang_name = read_string(cursor)?;
        let concrete = read_concrete(cursor)?;
        concretes.insert(Language(lang_name), concrete);
    }
    Ok(concretes)
}

fn read_concrete(cursor: &mut Cursor<&[u8]>) -> Result<Concrete, PgfError> {
    let offset = cursor.position();
    let name = read_string(cursor)?;
    let cflags = read_flags(cursor)?;
    let printnames = read_list(cursor, read_printname)?;
    let sequences = read_list(cursor, |c| read_list(c, read_symbol))?;
    let cncfuns = read_list(cursor, read_cncfun)?;
    let lindefs = read_list(cursor, read_lindef)?;
    let productions = read_list(cursor, read_production_set)?
        .into_iter()
        .map(|ps| (ps.cat, ps.prods))
        .collect();
    let cnccats = read_list(cursor, read_cnccat)?
        .into_iter()
        .map(|cc| (cc.name.clone(), cc))
        .collect();
    let total_cats = read_int(cursor)?;
    Ok(Concrete {
        cflags,
        productions,
        cncfuns,
        sequences,
        cnccats,
        printnames,
        lindefs,
        total_cats,
    })
}

fn read_printname(cursor: &mut Cursor<&[u8]>) -> Result<PrintName, PgfError> {
    let name = read_string(cursor)?;
    let printname = read_string(cursor)?.0;
    Ok(PrintName { name, printname })
}

fn read_lindef(cursor: &mut Cursor<&[u8]>) -> Result<LinDef, PgfError> {
    let cat = read_int(cursor)?;
    let funs = read_list(cursor, read_int)?;
    Ok(LinDef { cat, funs })
}

fn read_production_set(cursor: &mut Cursor<&[u8]>) -> Result<ProductionSet, PgfError> {
    let cat = read_int(cursor)?;
    let prods = read_list(cursor, read_production)?;
    Ok(ProductionSet { cat, prods })
}

struct ProductionSet {
    cat: i32,
    prods: Vec<Production>,
}

fn read_production(cursor: &mut Cursor<&[u8]>) -> Result<Production, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read production tag: {}", e) })?;
    match tag {
        0 => {
            let fid = read_int(cursor)?;
            let args = read_list(cursor, read_parg)?;
            Ok(Production::Apply { fid, args })
        }
        1 => {
            let arg = cursor.read_i8()
                .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read coerce arg: {}", e) })? as i32;
            Ok(Production::Coerce { arg })
        }
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown production tag: {}", tag) }),
    }
}

fn read_parg(cursor: &mut Cursor<&[u8]>) -> Result<PArg, PgfError> {
    let hypos = read_list(cursor, read_int)?;
    let fid = read_int(cursor)?;
    Ok(PArg { hypos, fid })
}

fn read_cncfun(cursor: &mut Cursor<&[u8]>) -> Result<CncFun, PgfError> {
    let name = read_string(cursor)?;
    let lins = read_list(cursor, read_int)?;
    Ok(CncFun { name, lins })
}

fn read_cnccat(cursor: &mut Cursor<&[u8]>) -> Result<CncCat, PgfError> {
    let name = read_string(cursor)?;
    let start = read_int(cursor)?;
    let end = read_int(cursor)?;
    let labels = read_list(cursor, |c| Ok(read_string(c)?.0))?;
    Ok(CncCat { name, start, end, labels })
}

fn read_symbol(cursor: &mut Cursor<&[u8]>) -> Result<Symbol, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read symbol tag: {}", e) })?;
    match tag {
        0 => {
            let i = read_int(cursor)?;
            let label = read_int(cursor)?;
            Ok(Symbol::SymCat(i, label))
        }
        1 => {
            let i = read_int(cursor)?;
            let label = read_int(cursor)?;
            Ok(Symbol::SymLit(i, label))
        }
        2 => {
            let i = read_int(cursor)?;
            let var = read_int(cursor)?;
            Ok(Symbol::SymVar(i, var))
        }
        3 => Ok(Symbol::SymKS(read_string(cursor)?.0)),
        4 => {
            let tokens = read_list(cursor, |c| Ok(read_string(c)?.0))?;
            let alts = read_list(cursor, read_alt)?;
            Ok(Symbol::SymKP(tokens, alts))
        }
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown symbol tag: {}", tag) }),
    }
}

fn read_alt(cursor: &mut Cursor<&[u8]>) -> Result<Alt, PgfError> {
    let tokens = read_list(cursor, |c| Ok(read_string(c)?.0))?;
    let prefixes = read_list(cursor, |c| Ok(read_string(c)?.0))?;
    Ok(Alt { tokens, prefixes })
}

fn read_list<T, F>(cursor: &mut Cursor<&[u8]>, f: F) -> Result<Vec<T>, PgfError>
where
    F: Fn(&mut Cursor<&[u8]>) -> Result<T, PgfError>,
{
    let offset = cursor.position();
    let len = read_int(cursor)?;
    let mut result = Vec::with_capacity(len as usize);
    for _ in 0..len {
        result.push(f(cursor)?);
    }
    Ok(result)
}

pub fn pgf_to_json(pgf: &Pgf) -> Result<String, PgfError> {
    let json = json!({
        "abstract": abstract_to_json(&pgf.absname, &pgf.startcat, &pgf.r#abstract),
        "concretes": concretes_to_json(&pgf.concretes),
    });
    serde_json::to_string_pretty(&json)
        .map_err(|e| PgfError::SerializeError(e.to_string()))
}

fn abstract_to_json(name: &CId, startcat: &CId, abs: &Abstract) -> JsonValue {
    json!({
        "name": cid::show_cid(name),
        "startcat": cid::show_cid(startcat),
        "funs": abs.funs.iter().map(|(cid, fun)| {
            let (args, cat) = cat_skeleton(&fun.ty);
            (cid::show_cid(cid), json!({
                "args": args.into_iter().map(|c| cid::show_cid(&c)).collect::<Vec<_>>(),
                "cat": cid::show_cid(&cat),
                "arity": fun.arity,
                "is_constructor": fun.is_constructor,
                "prob": fun.prob,
            }))
        }).collect::<HashMap<_, _>>(),
    })
}

fn concretes_to_json(concretes: &HashMap<Language, Concrete>) -> JsonValue {
    json!(concretes.iter().map(|(lang, cnc)| {
        (cid::show_cid(&lang.0), concrete_to_json(cnc))
    }).collect::<HashMap<_, _>>())
}

fn concrete_to_json(cnc: &Concrete) -> JsonValue {
    json!({
        "flags": cnc.cflags.iter().map(|(k, v)| (cid::show_cid(k), literal_to_json(v))).collect::<HashMap<_, _>>(),
        "productions": cnc.productions.iter().map(|(cat, prods)| {
            (*cat, prods.iter().map(production_to_json).collect::<Vec<_>>())
        }).collect::<HashMap<_, _>>(),
        "functions": cnc.cncfuns.iter().map(cnc_fun_to_json).collect::<Vec<_>>(),
        "sequences": cnc.sequences.iter().map(|seq| sequence_to_json(seq)).collect::<Vec<_>>(),
        "categories": cnc.cnccats.iter().map(|(c, cat)| (cid::show_cid(c), cnc_cat_to_json(cat))).collect::<HashMap<_, _>>(),
        "printnames": cnc.printnames.iter().map(|pn| json!({
            "name": cid::show_cid(&pn.name),
            "printname": pn.printname,
        })).collect::<Vec<_>>(),
        "lindefs": cnc.lindefs.iter().map(|ld| json!({
            "cat": ld.cat,
            "funs": ld.funs,
        })).collect::<Vec<_>>(),
        "totalfids": cnc.total_cats,
    })
}

fn literal_to_json(lit: &Literal) -> JsonValue {
    match lit {
        Literal::Str(s) => json!(s),
        Literal::Int(n) => json!(n),
        Literal::Flt(d) => json!(d),
    }
}

fn cnc_cat_to_json(cat: &CncCat) -> JsonValue {
    json!({
        "start": cat.start,
        "end": cat.end,
        "labels": cat.labels,
    })
}

fn cnc_fun_to_json(fun: &CncFun) -> JsonValue {
    json!({
        "name": cid::show_cid(&fun.name),
        "lins": fun.lins,
    })
}

fn production_to_json(prod: &Production) -> JsonValue {
    match prod {
        Production::Apply { fid, args } => json!({
            "type": "Apply",
            "fid": fid,
            "args": args.iter().map(p_arg_to_json).collect::<Vec<_>>(),
        }),
        Production::Coerce { arg } => json!({
            "type": "Coerce",
            "arg": arg,
        }),
    }
}

fn p_arg_to_json(arg: &PArg) -> JsonValue {
    json!({
        "type": "PArg",
        "hypos": &arg.hypos,
        "fid": arg.fid,
    })
}

fn sequence_to_json(seq: &[Symbol]) -> JsonValue {
    json!(seq.iter().map(symbol_to_json).collect::<Vec<_>>())
}

fn symbol_to_json(sym: &Symbol) -> JsonValue {
    match sym {
        Symbol::SymCat(n, l) => json!({"type": "SymCat", "args": [n, l]}),
        Symbol::SymLit(n, l) => json!({"type": "SymLit", "args": [n, l]}),
        Symbol::SymVar(n, l) => json!({"type": "SymVar", "args": [n, l]}),
        Symbol::SymKS(t) => json!({"type": "SymKS", "args": [t]}),
        Symbol::SymKP(ts, alts) => json!({"type": "SymKP", "args": [
            ts,
            alts.iter().map(alt_to_json).collect::<Vec<_>>()
        ]}),
        Symbol::SymNE => json!({"type": "SymNE", "args": []}),
    }
}

fn alt_to_json(alt: &Alt) -> JsonValue {
    json!({
        "type": "Alt",
        "args": [
            alt.tokens,
            alt.prefixes,
        ]
    })
}

fn cat_skeleton(ty: &Type) -> (Vec<CId>, CId) {
    (ty.hypos.iter().map(|h| h.ty.category.clone()).collect(), ty.category.clone())
}

pub fn parse(pgf: &Pgf, lang: &Language, typ: &Type, input: &str) -> Result<Vec<Expr>, PgfError> {
    let tokens = input.split_whitespace().map(|s| s.to_string()).collect::<Vec<_>>();
    let mut state = parse::init_state(pgf, lang, typ)?;

    for token in tokens {
        parse::next_state(&mut state, parse::ParseInput { token })?;
    }

    let (output, _bracketed) = parse::get_parse_output(&state, typ, Some(4));
    match output {
        parse::ParseOutput::ParseOk(trees) => Ok(trees),
        parse::ParseOutput::ParseFail => Err(PgfError::ParseError("Parsing failed".to_string())),
    }
}

pub fn check_expr(pgf: &Pgf, expr: &Expr, expected: &Type) -> Result<(Expr, Type), PgfError> {
    match expr {
        Expr::Fun(cid) => {
            let fun_type = pgf.r#abstract.funs.get(cid)
                .ok_or_else(|| PgfError::TypeCheckError(format!("Unknown function: {}", cid::show_cid(cid))))?
                .ty.clone();
            if fun_type.category == expected.category {
                Ok((expr.clone(), fun_type))
            } else {
                Err(PgfError::TypeCheckError(format!(
                    "Type mismatch: expected {}, got {}",
                    cid::show_cid(&expected.category),
                    cid::show_cid(&fun_type.category)
                )))
            }
        }
        Expr::App(e1, e2) => {
            let (e1_checked, e1_type) = check_expr(pgf, e1, expected)?;
            let (args, result_cat) = cat_skeleton(&e1_type);
            if args.is_empty() || result_cat != expected.category {
                return Err(PgfError::TypeCheckError("Invalid application".to_string()));
            }
            let arg_type = &args[0];
            let (e2_checked, _e2_type) = check_expr(pgf, e2, &Type {
                hypos: vec![],
                category: arg_type.clone(),
                exprs: vec![],
            })?;
            Ok((Expr::App(Box::new(e1_checked), Box::new(e2_checked)), expected.clone()))
        }
        _ => Err(PgfError::TypeCheckError("Unsupported expression for type checking".to_string())),
    }
}

pub fn linearize(pgf: &Pgf, lang: &Language, expr: &Expr) -> Result<String, PgfError> {
    let cnc = pgf.concretes.get(lang).ok_or_else(|| PgfError::UnknownLanguage(cid::show_cid(&lang.0)))?;
    match expr {
        Expr::Fun(cid) => {
            let cnc_fun = cnc.cncfuns.iter().find(|f| f.name == *cid);
            if let Some(fun) = cnc_fun {
                let seq = fun.lins.iter()
                    .filter_map(|&i| cnc.sequences.get(i as usize))
                    .flat_map(|seq| seq.iter().filter_map(|sym| match sym {
                        Symbol::SymKS(s) => Some(s.clone()),
                        Symbol::SymKP(tokens, alts) => Some(tokens.first().cloned().unwrap_or_default()),
                        _ => None,
                    }))
                    .collect::<Vec<_>>();
                Ok(seq.join(" "))
            } else {
                Err(PgfError::ParseError("Function not found in concrete syntax".to_string()))
            }
        }
        Expr::App(e1, e2) => {
            let s1 = linearize(pgf, lang, e1)?;
            let s2 = linearize(pgf, lang, e2)?;
            Ok(format!("{} {}", s1, s2))
        }
        _ => Err(PgfError::ParseError("Unsupported expression for linearization".to_string())),
    }
}

pub fn categories(pgf: &Pgf) -> Vec<CId> {
    pgf.r#abstract.cats.keys().cloned().collect()
}

pub fn category_context(pgf: &Pgf, cat: &CId) -> Option<Vec<Hypo>> {
    pgf.r#abstract.cats.get(cat).map(|c| c.hypos.clone())
}

pub fn functions(pgf: &Pgf) -> Vec<CId> {
    pgf.r#abstract.funs.keys().cloned().collect()
}

pub fn functions_by_cat(pgf: &Pgf, cat: &CId) -> Vec<CId> {
    pgf.r#abstract
        .cats
        .get(cat)
        .map(|c| c.funs.iter().map(|(_, cid)| cid.clone()).collect())
        .unwrap_or_default()
}

pub fn function_type(pgf: &Pgf, fun: &CId) -> Option<Type> {
    pgf.r#abstract.funs.get(fun).map(|f| f.ty.clone())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Write;

    #[test]
    fn test_synthetic_pgf_to_json() {
        let pgf = create_test_pgf();
        let json = pgf_to_json(&pgf).expect("Failed to convert PGF to JSON");
        let mut file = File::create("foods.json").expect("Failed to create output file");
        file.write_all(json.as_bytes()).expect("Failed to write JSON");
        let json_value: serde_json::Value = serde_json::from_str(&json).expect("Invalid JSON");
        assert!(json_value.get("abstract").is_some(), "JSON missing 'abstract' field");
        assert!(json_value.get("concretes").is_some(), "JSON missing 'concretes' field");
    }

    fn create_test_pgf() -> Pgf {
        let mut funs = HashMap::new();
        funs.insert(cid::mk_cid("Pred"), Function {
            ty: Type { hypos: vec![], category: cid::mk_cid("Comment"), exprs: vec![] },
            weight: 1,
            equations: None,
            arity: 0,
            is_constructor: true,
            prob: 1.0,
        });
        funs.insert(cid::mk_cid("This"), Function {
            ty: Type { hypos: vec![], category: cid::mk_cid("Item"), exprs: vec![] },
            weight: 1,
            equations: None,
            arity: 0,
            is_constructor: true,
            prob: 1.0,
        });

        let mut cats = HashMap::new();
        cats.insert(cid::mk_cid("Comment"), Category { hypos: vec![], funs: vec![(0, cid::mk_cid("Pred"))] });
        cats.insert(cid::mk_cid("Item"), Category { hypos: vec![], funs: vec![(0, cid::mk_cid("This"))] });

        let abstract_syntax = Abstract { funs, cats };

        let mut concretes = HashMap::new();
        let mut cncfuns = Vec::new();
        cncfuns.push(CncFun { name: cid::mk_cid("Pred"), lins: vec![0] });
        cncfuns.push(CncFun { name: cid::mk_cid("This"), lins: vec![1] });

        let mut sequences = Vec::new();
        sequences.push(vec![Symbol::SymKS("is".to_string())]);
        sequences.push(vec![Symbol::SymKS("this".to_string())]);

        let mut cnccats = HashMap::new();
        cnccats.insert(cid::mk_cid("Comment"), CncCat { name: cid::mk_cid("Comment"), start: 0, end: 1, labels: vec!["C1".to_string()] });
        cnccats.insert(cid::mk_cid("Item"), CncCat { name: cid::mk_cid("Item"), start: 1, end: 2, labels: vec!["I1".to_string()] });

        let concrete = Concrete {
            cflags: HashMap::new(),
            productions: HashMap::new(),
            cncfuns,
            sequences,
            cnccats,
            printnames: vec![],
            lindefs: vec![],
            total_cats: 2,
        };

        concretes.insert(Language(cid::mk_cid("FoodEng")), concrete);

        Pgf {
            absname: cid::mk_cid("Food"),
            concretes,
            r#abstract: abstract_syntax,
            startcat: cid::mk_cid("Comment"),
            flags: HashMap::new(),
        }
    }

    #[test]
    fn test_synthetic_parse_sentence() {
        let pgf = create_test_pgf();
        let lang = language::read_language("FoodEng").expect("Invalid language");
        let typ = types::start_cat(&pgf);
        let mut state = parse::init_state(&pgf, &lang, &typ).expect("Failed to initialize parse state");
        parse::next_state(&mut state, parse::ParseInput { token: "is".to_string() }).expect("Failed to parse token");
        let (output, _bracketed) = parse::get_parse_output(&state, &typ, Some(4));
        match output {
            parse::ParseOutput::ParseOk(_) => println!("Parse succeeded"),
            parse::ParseOutput::ParseFail => println!("Parse failed"),
        }
    }

    #[test]
    fn test_invalid_pgf() {
        let invalid_data = Bytes::from(vec![0, 1, 2, 3]);
        let result = parse_pgf(invalid_data);
        assert!(matches!(result, Err(PgfError::DeserializeError { .. })), "Expected deserialization error");
    }

    #[test]
    fn test_real_pgf_parsing() {
        let pgf = read_pgf("./grammars/Hello/Hello.pgf").expect("Failed to read PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert to JSON");
        let mut file = File::create("hello.json").expect("Failed to create output file");
        file.write_all(json.as_bytes()).expect("Failed to write JSON");
    }
}