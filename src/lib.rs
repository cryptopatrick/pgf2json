#![allow(unused)]

//! This module adds support for binary parsing of PGF binary files.
//!
//! This module implements a parser for the Portable Grammar Format (PGF) 
//! version 1.0, as specified in this document. It includes functionality for 
//! parsing PGF binary files, type checking, linearization, and JSON serialization. 
//! The code handles, among other things; correct version handling, full type 
//! and expression parsing, proper string length parsing, and support for 
//! equations, patterns, print names, and linearization definitions.
//! 
//! This first part of the module documentation is a reference for the exact 
//! format of PGF. The format described here is a version 1.0.
//!
//! The Haskell GF compiler can dump any PGF file into textual representation 
//! with a syntax close to what's used here. We can do so by using the following
//! command:
//!
//! > gf -make -output-format=pgf_pretty grammar_spec.pgf
//!
//! # Portal Grammar Format Specification | Version 1.0
//! 
//! ### Basic Types
//!
//! The Portable Grammar Format is a binary format where the structures of the
//! grammar are serialized as a sequence of bytes. Every structure is a list of
//! sequentially serialized fields, where every field is either another
//! structure or has a basic type. The allowed basic types are:
//!
//! - ﻿﻿Int8 - 8 bits integer, with sign, represented as a single byte.
//! - ﻿﻿Int16 - 16 bits integer, with sign, represented as a sequence of two
//! bytes where the most significant byte is stored first.
//! - ﻿﻿Int - a 32 bits integer with sign encoded as a sequence of bytes with
//! variable length. The last bit of every byte is an indication for whether
//! there are more bytes left. If the bit is 1, then there is at least one more
//! byte to be read, otherwise this is the last byte in the sequence.
//! The other 7 bits are parts of the stored integer. We store the bits from the
//!  least significant to the most significant.
//! - ﻿﻿String - a string in UTF-8 encoding. We first store as Int (a variable
//! length integer) the length of the string in number of Unicode characters and
//!  after that we add the UTF-8 encoding of the string itself.
//! - ﻿﻿Float - A double precision floating point number serialized in a
//! big-endian format following the IEEE754 standard.
//! - ﻿﻿List - Many of the object fields are lists of other objects.
//! We say that the field is of type [Object] if it contains a list of objects
//! of type Object. The list is serialized as a variable length integer
//! indicating the length of the list in number of objects, followed by the
//! serialization of the elements of the list.
//!
//! ---
//! ### PGF
//!
//! The whole PGF file contains only one structure which corresponds to the
//! abstract structure $G$ from Definition 1 in Section 2.1.
//! The structure has the following fields:
//!
//! | **type** | **description**                 |
//! | -------- | ------------------------------- |
//! | Int16    | major PGF version, should be 1. |
//! | Int16   | minor PGF version, should be 0. |
//! | [Flag]   | global flags                    |
//! | Abstract | abstract syntax                 |
//! | Concrete | list of concrete syntaxes       |
//! If PGF is changed in the future, the version in the first two fields should be updated.
//! The implementations can use the version number to maintain backward compatibility.
//!
//! ---
//! ### Flag
//!
//! The flags are pairs of a name and a literal and store different configuration parameters.
//! They are generated by the compiler and are accessible only internally from the interpreter.
//! By using flags we can add new settings without changing the format.
//!
//! | type    | description |
//! | ------- | ----------- |
//! | String  | flag name   |
//! | Literal | flag value  |
//!
//! ---
//! ### Abstract
//!
//! This is the object that represents the abstract syntax A (Definition 2, Section 2.1) 
//! of a grammar. The name of the abstract syntax is the name of the top-level 
//! abstract module in the grammar. The start category is specified with the flag startcat.
//!
//! | type     | description                     |
//! | -------- | ------------------------------- |
//! | String   | the name of the abstract syntax |
//! | [Flag]   | a list of flags                 |
//! | [AbsFun] | a list of abstract functions    |
//! | [AbsCat] | a list of abstract categories   |
//! Note: all lists are sorted by name which makes it easy to do binary search.
//!
//! ---
//! ### AbsFun
//!
//! Every abstract function is represented with one AbsFun object.
//!
//! | **type**   | **description**                                                     |
//! | ---------- | ------------------------------------------------------------------- |
//! | String     | the name of the function                                            |
//! | Type       | function's type signature                                           |
//! | Int        | function's arity                                                    |
//! | Int8       | a constructor tag: 0 - constructor; 1 - function                    |
//! | [Equation] | definitional equations for this function if it is not a constructor |
//! | Float      | the probability of the function                                     |
//! The constructor tag distinguishes between constructors and computable functions, i.e. we can distinguish between this two judgements:
//!
//! - ﻿﻿constructor: __data__ $f: T$
//! - ﻿﻿function: __fun__ $f: T$
//!
//! If this is a function, then we also include a list of definitional equations. The list can be empty which means that the function is an axiom. In the cases, when we have at least one equation then the arity is the number of arguments that have to be known in order to do pattern matching. For constructors or axioms the arity is zero.
//!
//! ---
//! ### AbsCat
//!
//! Every abstract category is represented with one AbsCat object. The object includes the name and the type information for the category plus a list of all functions whose return type is this category. The functions are listed in the order in which they appear in the source code.
//!
//! | type     | description                              |
//! | -------- | ---------------------------------------- |
//! | String   | the name of the category                 |
//! | [Hypo]   | a list of hypotheses                     |
//! | [CatFun] | a list of functions in source-code order |
//!
//! ---
//! ### CatFun
//!
//! This object is used internally to keep a list of abstract functions with their probabilities.
//!
//! | type   | description                     |
//! | ------ | ------------------------------- |
//! | String | the name of the function        |
//! | Float  | the probability of the function |
//!
//! ---
//! ### Type
//!
//! This is the description of an abstract syntax type. Since the types are monomorphic and in normal form, they have the general form:
//!
//! $$(X_1 : T_1) → (x_2 : T_2) → ... → (x_n: T_n) → C e_1... e_n$$
//!
//! The list of hypotheses $(x_i: T_i)$ is stored as a list of Hypo objects and the indices $e_1 ... e_n$ are stored as a list of expressions.
//!
//! | type         | description                                  |
//! | ------------ | -------------------------------------------- |
//! | [Hypo]       | a list of hypotheses                         |
//! | String       | the name of the category in the return type |
//! | [Expression] | indices in the return type                   |
//!
//! ---
//! ### Hypo
//!
//! Every Hypo object represents an argument in some function type. Since we support implicit and explicit arguments, the first field tells us whether we have explicit argument i.e. $(x: T)$ or implicit i.e. $(\{x\} : T)$. The next two fields are the name of the bound variable and its type. If no variable is bound then the name is $'_'$.
//!
//! | type     | description                                      |
//! | -------- | ------------------------------------------------ |
//! | BindType | the binding type i.e. implicit/explicit argument |
//! | String   | a variable name or $'_'$ if no variable is bound |
//! | Type     | the type of the variable                         |
//!
//! ---
//!
//! ### Equation
//!
//! Every computable function is represented with a list of equations where the equation is a pair of list of patterns and an expression. All equations must have the same number of patterns which is equal to the arity of the function.
//!
//! | type       | description              |
//! | ---------- | ------------------------ |
//! | [Pattern]  | a sequence of patterns   |
//! | Expression | an expression            |
//!
//! ---
//!
//! ### Pattern
//!
//! This is the representation of a single pattern in a definitional equation for computable function. The first field is a tag which encodes the kind of pattern.
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | a tag       |
//!
//! 1. ﻿﻿﻿tag=0 - pattern matching on constructor application (i.e. $c\; p_1 \;  p_2 ... p_n$)
//!
//! | type      | description                                 |
//! | --------- | ------------------------------------------- |
//! | String    | the name of the constructor                 |
//! | [Pattern] | a list of nested patterns for the arguments |
//!
//! 2. ﻿﻿﻿tag=1 - a variable type
//!
//! | type   | description       |
//! | ------ | ----------------- |
//! | String | the variable name |
//!
//! 3. ﻿﻿﻿tag=2 - a pattern which binds a variable but also does nested pattern matching (i.e. $x@p$) 
//!
//! | type    | description       |
//! | ------- | ----------------- |
//! | String  | the variable name |
//! | Pattern | a nested pattern  |
//!
//! 4. ﻿﻿﻿tag=3 - a wildcard (i.e. $_$).
//!
//! 5. ﻿﻿﻿tag=4 - matching a literal i.e. string, integer or float
//!
//! | type    | description              |
//! | ------- | ------------------------ |
//! | Literal | the value of the literal |
//!
//! 6. ﻿﻿﻿tag=5 - pattern matching on an implicit argument (i.e. $\{{P}\}$)
//!
//! | type      | description        |
//! | --------- | ------------------ |
//! | [Pattern] | the nested pattern |
//!
//! 7. tag=6 - an inaccessible pattern $(\sim p)$
//!
//! | type | description        |
//! | ---- | ------------------ |
//! | Expr | the nested pattern |
//!
//! ---
//!
//!
//!
//! ### Expression
//!
//! This is the encoding of an abstract syntax expression (tree).
//!
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | a tag       |
//!
//! 1. ﻿﻿﻿tag=0 - a lambda abstraction (i.e. $\\\x → ...$)
//!
//! | type       | description                          |
//! | ---------- | ------------------------------------ |
//! | BindType   | a tag for implicit/explicit argument |
//! | String     | the variable name                    |
//! | Expression | the body of the lambda abstraction   |
//!
//! 2. ﻿﻿﻿tag=1 - application (i.e. $f x$)
//!
//! | type       | description                        |
//! | ---------- | ---------------------------------- |
//! | Expression | the left-hand expression           |
//! | Expression | the right-hand expression          |
//! 3. ﻿﻿﻿tag=2 - a literal value i.e. string, integer or float type description
//!
//! | type    | description              |
//! | ------- | ------------------------ |
//! | Literal | the value of the literal |
//! 4. ﻿﻿﻿tag=3 - a metavariable (i.e. $?0, ?1,...$)
//!
//! | type | description                |
//! | ---- | -------------------------- |
//! | Int  | the id of the metavariable |
//!
//! 5. ﻿﻿﻿tag=4 - an abstract syntax function
//!
//! | type       | description                        |
//! | ---------- | ---------------------------------- |
//! | String     | the function name                  |
//!
//! 6. tag=5 - a variable
//!
//! | type | description                         |
//! | ---- | ----------------------------------- |
//! | Int  | the de Bruijn index of the variable |
//!
//! 7. tag=6 - an expression with a type annotation (i.e. $(e: t)$)
//!
//! | type       | description                |
//! | ---------- | -------------------------- |
//! | Expression | the annotated expression   |
//! | Type       | the type of the expression |
//!
//! 8. tag=7 - an implicit argument (i.e. $\{e\}$)
//!
//! | type       | description                     |
//! | ---------- | ------------------------------- |
//! | Expression | the expression for the argument |
//!
//! ---
//! ### Literal
//!
//! The Literal object represents the built-in kinds of literal constants. It starts with a tag which encodes the type of the constant:
//!
//! | type | description  |
//! | ---- | ------------ |
//! | Int8 | literal type |
//!
//! Currently we support only three types of literals:
//!
//! 1. ﻿﻿﻿tag=0 - string type
//!
//! | type   | description |
//! | ------ | ----------- |
//! | String | the value   |
//!
//!
//! 2. ﻿﻿﻿tag=1 - integer
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int  | the value   |
//!
//! 3. ﻿﻿﻿tag=2 - float type
//!
//! | type  | description |
//! | ----- | ----------- |
//! | Float | the value   |
//!
//! ---
//!
//!
//! ### BindType
//!
//! The bind type is a tag which encodes whether we have an explicit or an implicit argument.
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | tag         |
//!
//! ---
//!
//!
//! ### Concrete
//!
//! Every concrete syntax C (Definition 3, Section 2.1), in the grammar, is represented with an object. The name of the concrete syntax is the name of the top-level concrete module in the grammar.
//!
//! | type            | description                                                   |
//! | --------------- | ------------------------------------------------------------- |
//! | String          | the name of the concrete syntax                               |
//! | [Flag]          | a list of flags                                               |
//! | [PrintName]     | a list of print names                                         |
//! | [Sequence]      | a table with sequences (Section 2.8.1)                        |
//! | [CncFun]        | a list of concrete functions                                  |
//! | [LinDef]        | a list of functions for default linearization                 |
//! | [ProductionSet] | a list of production sets                                     |
//! | [CncCat]        | a list of concrete categories                                 |
//! | Int             | total number of concrete categories allocated for the grammar |
//! _Note:_ The lists Flag, PrintName and CncCat are sorted by name which makes it easy to do binary search.
//! _Note:_ The total number of concrete categories is used by the parser to determine whether a given category is part of the grammar, i.e. member of $N^C$, or it was created during the parsing. This is the way to decide when to put metavariables during the tree extraction (Section 2.3.7).
//!
//! ---
//! ### PrintName
//!
//! Every function or category can have a print name which is a user friendly name that can be displayed in the user interface instead of the real one. The print names are defined in the concrete syntax which makes it easier to localize the user interface to different languages.
//!
//! | type   | description                              |
//! | ------ | ---------------------------------------- |
//! | String | the name of the function or the category |
//! | String | the printable name                       |
//!
//! ---
//!
//! ### Sequence
//!
//! This is the representation of a single sequence in PMCFG, produced during the common subexpression optimization (Section 2.8.1).
//!
//! | type     | description       |
//! | -------- | ----------------- |
//! | [Symbol] | a list of symbols |
//!
//! ---
//!
//! ### Symbol
//!
//! The Symbol (Definition 4, Section 2.1) represents either a terminal or a function argument in some sequence. The representation starts with a tag encoding the type of the symbol:
//!
//! | type | description    |
//! | ---- | -------------- |
//! | Int8 | expression tag |
//!
//! The supported symbols are:
//!
//! 1. ﻿﻿﻿tag=0. This is the representation of an argument, i.e. a pair $\langle k; l \rangle$ ) where $k$ is the argument index and $l$ is the constituent index.
//!
//! | type | description       |
//! | ---- | ----------------- |
//! | Int  | argument index    |
//! | Int  | constituent index |
//!
//! 2. ﻿﻿﻿tag=1 This is again an argument but we use different tag to indicate that the target can be a literal category (see Section 2.6). If the target category is not a new fresh category, generated by the parser, then it is treated as a literal category. In the pgf_pretty format, we print this kind of symbols as $\{d; r\}$ instead of $\langle d; r  \rangle$ .
//!
//! | type | description       |
//! | ---- | ----------------- |
//! | Int  | argument index    |
//! | Int  | constituent index |
//!
//! 3. ﻿﻿﻿tag=2 A high-order argument i.e. $\langle d; \$r)$ (Section 2.7).
//!
//! | type | description     |
//! | ---- | --------------- |
//! | Int  | argument index  |
//! | Int  | variable number |
//!
//! 4.  ﻿﻿﻿tag=3 This is a terminal symbol and represents a list of tokens.
//!
//! | type     | description        |
//! | -------- | ------------------ |
//! | [String] | sequence of tokens |
//!
//! 5. ﻿﻿﻿tag=4 An alternative terminal symbol representing phrase, whose form depends on the prefix of the next token. It corresponds to the __pre__ construction in GF and encodes variations like a/an in English.
//!
//! | type          | description                |
//! | ------------- | -------------------------- |
//! | [String]      | the default form           |
//! | [Alternative] | a sequence of alternatives |
//!
//! ---
//!
//! ### Alternative
//!
//! Every Alternative represents one possible form of a phrase which is dependent on the prefix of the next token. For example when the construction:
//!
//! $$pre \{\text{"beau"}; \text{"bel"/"'ami"}\}$$
//!
//! is compiled then the alternative bel / ami will be represented by the pair (["bel"],[" ami"]).
//!
//! | type     | description                                  |
//! | -------- | -------------------------------------------- |
//! | [String] | The tokens to use if the prefix matches      |
//! | [String] | The prefix matched with the following tokens |
//!
//! ---
//! ### CncFun
//!
//! This is the definition of a single concrete function (Definition 4, Section
//! 2.1). The first field is the name of the corresponding abstract function
//! which gives us the direct definition of the $\psi_F$ mapping. The second
//! field is the function definition given as a list of indices pointing to the
//! sequences table (see the Concrete object).
//!
//! | type   | description                                     |
//! | ------ | ----------------------------------------------- |
//! | String | the name of the corresponding abstract function |
//! | [Int]  | list of indices into the sequences array        |
//!
//! ---
//!
//! ### LinDef
//!
//! The LinDef object stores the list of all concrete functions that can be used for the default linearization of some concrete category (Section 2.5).
//!
//! | type  | description                  |
//! | ----- | ---------------------------- |
//! | Int   | the concrete category        |
//! | [Int] | a list of concrete functions |
//!
//! ---
//!
//! ### ProductionSet
//!
//! A group of productions with the same result category. The productions are grouped because this makes it easier for the parser to find the relevant productions in the prediction step:
//!
//! | type         | description           |
//! | ------------ | --------------------- |
//! | Int          | the result category   |
//! | [Production] | a list of productions |
//!
//! ---
//!
//! ### Production
//!
//! The production can be either an application of some function or a coercion.
//!
//! | type | description |
//! | ---- | ----------- |
//! | Int8 | tag         |
//! 1. tag=0 the production is an application (Definition 4, Section 2.1):
//!
//! | type   | description           |
//! | ------ | --------------------- |
//! | Int    | the concrete function |
//! | [PArg] | a list of arguments   |
//!
//! 2. tag=1 the production is a coercion (Section 2.8.1):
//!
//! | type | description         |
//! | ---- | ------------------- |
//! | Int8 | a concrete category |
//!
//! ---
//! ### PArg
//!
//! An argument in a production.
//!
//! | type  | description                                              |
//! | ----- | -------------------------------------------------------- |
//! | [Int] | the categories of the high-order arguments (Section 2.7) |
//! | Int   | a concrete category                                      |
//!
//! ---
//!
//! ### CncCat
//!
//! This is the representation of a set of concrete categories which map to the
//! same abstract category. Since all concrete categories generated from the
//! same abstract category are always represented as consecutive integers, here
//! we store only the first and the last category. The compiler also generates
//! a name for every constituent so here we have the list of names. The length
//! of the list is equal to the dimension of the category.
//!
//! | type     | description                                                   |
//! | -------- | ------------------------------------------------------------- |
//! | String   | the name of the corresponding (by $\psi_N$) abstract category |
//! | Int      | the first concrete category                                   |
//! | Int      | the last concrete category                                    |
//! | [String] | a list of constituent names
use byteorder::{BigEndian, ReadBytesExt};

use std::collections::HashMap;
use std::fs::File;
use std::io::{self, Cursor, Read};
use bytes::Bytes;
use serde::{Deserialize, Serialize};
use serde_json::{json, Value as JsonValue};
use thiserror::Error;

// Errors that can occur during PGF operations.
#[derive(Error, Debug)]
pub enum PgfError {
    #[error("IO error: {0}")]
    Io(#[from] io::Error),
    #[error("Unknown language: {0}")]
    UnknownLanguage(String),
    #[error("Deserialization error at offset {offset}: {message}")]
    DeserializeError { offset: u64, message: String },
    #[error("Serialization error: {0}")]
    SerializeError(String),
    #[error("Type checking error: {0}")]
    TypeCheckError(String),
    #[error("Parsing error: {0}")]
    ParseError(String),
}

// Represents a Portable Grammar Format (PGF) structure.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Pgf {
    absname: CId,
    concretes: HashMap<Language, Concrete>,
    r#abstract: Abstract,
    startcat: CId,
    flags: HashMap<CId, Literal>,
}


#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Abstract {
    funs: HashMap<CId, Function>,
    cats: HashMap<CId, Category>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Concrete {
    cflags: HashMap<CId, Literal>,
    productions: HashMap<i32, Vec<Production>>, // From cCats - changed to Vec for efficiency
    cncfuns: Vec<CncFun>,
    sequences: Vec<Vec<Symbol>>,
    cnccats: HashMap<CId, CncCat>,
    printnames: Vec<PrintName>,
    lindefs: Vec<LinDef>,
    linrefs: Vec<LinRef>,  // Missing field added
    ccats: Vec<CCat>,      // Missing field added  
    total_cats: i32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Function {
    ty: Type,
    weight: i32,
    equations: Option<Vec<Equation>>,
    arity: i32,
    is_constructor: bool,
    prob: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Category {
    hypos: Vec<Hypo>,
    funs: Vec<(usize, CId)>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct CId(String);

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Language(CId);

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct Hypo {
    binding: Binding,
    ty: Type,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum Binding {
    Explicit(String),
    Implicit(String),
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct Type {
    hypos: Vec<Hypo>,
    category: CId,
    exprs: Vec<Expr>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Literal {
    Str(String),
    Int(i32),
    Flt(f64),
}

impl PartialEq for Literal {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            (Literal::Str(a), Literal::Str(b)) => a == b,
            (Literal::Int(a), Literal::Int(b)) => a == b,
            (Literal::Flt(a), Literal::Flt(b)) => a.to_bits() == b.to_bits(),
            _ => false,
        }
    }
}

impl Eq for Literal {}

impl std::hash::Hash for Literal {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        match self {
            Literal::Str(s) => {
                0u8.hash(state);
                s.hash(state);
            }
            Literal::Int(i) => {
                1u8.hash(state);
                i.hash(state);
            }
            Literal::Flt(f) => {
                2u8.hash(state);
                f.to_bits().hash(state);
            }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct CncCat {
    name: CId,
    start: i32,
    end: i32,
    labels: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct CncFun {
    name: CId,
    lins: Vec<i32>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum Production {
    Apply { fid: i32, args: Vec<PArg> },
    Coerce { arg: i32 },
    Const { cid: CId, expr: Expr, tokens: Vec<String> },
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct PArg {
    hypos: Vec<i32>,
    fid: i32,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct PrintName {
    name: CId,
    printname: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct LinDef {
    cat: i32,
    funs: Vec<i32>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct LinRef {
    cat: i32,
    funs: Vec<i32>, 
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct CCat {
    id: i32,
    productions: Vec<Production>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum Symbol {
    SymCat(i32, i32),           // tag 0
    SymLit(i32, i32),           // tag 1  
    SymVar(i32, i32),           // tag 2
    SymKS(String),              // tag 3 - terminal string
    SymKP(Vec<String>, Vec<Alt>), // tag 4 - terminal phrase
    SymBind,                    // tag 5
    SymSoftBind,                // tag 6
    SymNE,                      // tag 7
    SymSoftSpace,               // tag 8
    SymCapital,                 // tag 9
    SymAllCapital,              // tag 10
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct Alt {
    tokens: Vec<String>,
    prefixes: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Equation {
    patterns: Vec<Pattern>,
    result: Expr,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Pattern {
    PApp(CId, Vec<Pattern>),
    PVar(CId),
    PBind(CId, Box<Pattern>),
    PWildcard,
    PLit(Literal),
    PImplicit(Vec<Pattern>),
    PInaccessible(Expr),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Expr {
    Abs(Binding, CId, Box<Expr>),
    App(Box<Expr>, Box<Expr>),
    Fun(CId),
    Str(String),
    Int(i32),
    Float(f32),
    Double(f64),
    Meta(i32),
    Typed(Box<Expr>, Type),
    ImplArg(Box<Expr>),
    Lit(Literal),
    Var(i32),
}

impl PartialEq for Expr {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            (Expr::Abs(b1, c1, e1), Expr::Abs(b2, c2, e2)) => b1 == b2 && c1 == c2 && e1 == e2,
            (Expr::App(e1a, e1b), Expr::App(e2a, e2b)) => e1a == e2a && e1b == e2b,
            (Expr::Fun(c1), Expr::Fun(c2)) => c1 == c2,
            (Expr::Str(s1), Expr::Str(s2)) => s1 == s2,
            (Expr::Int(i1), Expr::Int(i2)) => i1 == i2,
            (Expr::Float(f1), Expr::Float(f2)) => f1.to_bits() == f2.to_bits(),
            (Expr::Double(d1), Expr::Double(d2)) => d1.to_bits() == d2.to_bits(),
            (Expr::Meta(m1), Expr::Meta(m2)) => m1 == m2,
            (Expr::Typed(e1, t1), Expr::Typed(e2, t2)) => e1 == e2 && t1 == t2,
            (Expr::ImplArg(e1), Expr::ImplArg(e2)) => e1 == e2,
            (Expr::Lit(l1), Expr::Lit(l2)) => l1 == l2,
            (Expr::Var(v1), Expr::Var(v2)) => v1 == v2,
            _ => false,
        }
    }
}

impl Eq for Expr {}

impl std::hash::Hash for Expr {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        match self {
            Expr::Abs(b, c, e) => {
                0u8.hash(state);
                b.hash(state);
                c.hash(state);
                e.hash(state);
            }
            Expr::App(e1, e2) => {
                1u8.hash(state);
                e1.hash(state);
                e2.hash(state);
            }
            Expr::Fun(c) => {
                2u8.hash(state);
                c.hash(state);
            }
            Expr::Str(s) => {
                3u8.hash(state);
                s.hash(state);
            }
            Expr::Int(i) => {
                4u8.hash(state);
                i.hash(state);
            }
            Expr::Float(f) => {
                5u8.hash(state);
                f.to_bits().hash(state);
            }
            Expr::Double(d) => {
                6u8.hash(state);
                d.to_bits().hash(state);
            }
            Expr::Meta(m) => {
                7u8.hash(state);
                m.hash(state);
            }
            Expr::Typed(e, t) => {
                8u8.hash(state);
                e.hash(state);
                t.hash(state);
            }
            Expr::ImplArg(e) => {
                9u8.hash(state);
                e.hash(state);
            }
            Expr::Lit(l) => {
                10u8.hash(state);
                l.hash(state);
            }
            Expr::Var(v) => {
                11u8.hash(state);
                v.hash(state);
            }
        }
    }
}

pub mod cid {
    use super::CId;

    pub fn mk_cid(s: &str) -> CId {
        CId(s.to_string())
    }

    pub fn wild_cid() -> CId {
        CId("*".to_string())
    }

    pub fn show_cid(cid: &CId) -> String {
        cid.0.clone()
    }

    pub fn read_cid(s: &str) -> Option<CId> {
        if s.is_empty() {
            None
        } else {
            Some(CId(s.to_string()))
        }
    }
}

pub mod language {
    use super::{CId, Language, Pgf, Literal};

    pub fn show_language(lang: &Language) -> String {
        super::cid::show_cid(&lang.0)
    }

    pub fn read_language(s: &str) -> Option<Language> {
        super::cid::read_cid(s).map(Language)
    }

    pub fn languages(pgf: &Pgf) -> Vec<Language> {
        pgf.concretes.keys().cloned().collect()
    }

    pub fn language_code(pgf: &Pgf, lang: &Language) -> Option<String> {
        pgf.concretes.get(lang).and_then(|cnc| {
            cnc.cflags.get(&CId("language".to_string())).and_then(|lit| {
                match lit {
                    Literal::Str(s) => Some(s.replace('_', "-")),
                    _ => None,
                }
            })
        })
    }

    pub fn abstract_name(pgf: &Pgf) -> Language {
        Language(pgf.absname.clone())
    }
}

pub mod types {
    use super::{CId, Hypo, Type, Pgf};

    pub fn mk_type(hypos: Vec<Hypo>, cat: CId, exprs: Vec<super::Expr>) -> Type {
        Type {
            hypos,
            category: cat,
            exprs,
        }
    }

    pub fn mk_hypo(binding: super::Binding, ty: Type) -> Hypo {
        Hypo { binding, ty }
    }

    pub fn start_cat(pgf: &Pgf) -> Type {
        Type {
            hypos: vec![],
            category: pgf.startcat.clone(),
            exprs: vec![],
        }
    }
}

pub mod parse {
    use super::{Pgf, Language, Type, Expr, Production, Symbol, PgfError, CncFun, BracketedString, cid};
    use std::collections::HashMap;

    #[derive(Debug, Clone)]
    pub struct ParseState {
        pgf: Pgf,
        lang: Language,
        typ: Type,
        active_items: HashMap<i32, Vec<Item>>,
        passive_items: HashMap<i32, Vec<Item>>,
        tokens: Vec<String>,
        current_pos: usize,
    }

    #[derive(Debug, Clone)]
    pub struct Item {
        fid: i32,
        seqid: i32,
        dot: usize,
        args: Vec<(i32, Expr)>,
        tree: Option<Expr>,
    }

    #[derive(Debug, Clone)]
    pub struct ParseInput {
        pub token: String,
    }

    #[derive(Debug, Clone)]
    pub enum ParseOutput {
        ParseOk(Vec<Expr>),
        ParseFail,
    }

    pub fn init_state(pgf: &Pgf, lang: &Language, typ: &Type) -> Result<ParseState, PgfError> {
        let cnc = pgf.concretes.get(lang).ok_or_else(|| PgfError::UnknownLanguage(cid::show_cid(&lang.0)))?;
        let cat_id = cnc.cnccats.get(&typ.category)
            .map(|cat| cat.start)
            .ok_or_else(|| PgfError::ParseError(format!("Category not found: {}", cid::show_cid(&typ.category))))?;
        let mut active_items = HashMap::new();
        if let Some(prods) = cnc.productions.get(&cat_id) {
            for prod in prods {
                if let Production::Apply { fid, args: _ } = prod {
                    let item = Item {
                        fid: *fid,
                        seqid: cnc.cncfuns.get(*fid as usize).map(|f| f.lins.get(0).copied().unwrap_or(0)).unwrap_or(0),
                        dot: 0,
                        args: vec![],
                        tree: None,
                    };
                    active_items.entry(cat_id).or_insert_with(Vec::new).push(item);
                }
            }
        }
        Ok(ParseState {
            pgf: pgf.clone(),
            lang: lang.clone(),
            typ: typ.clone(),
            active_items,
            passive_items: HashMap::new(),
            tokens: vec![],
            current_pos: 0,
        })
    }

    pub fn next_state(state: &mut ParseState, input: ParseInput) -> Result<(), PgfError> {
        state.tokens.push(input.token.clone());
        let cnc = state.pgf.concretes.get(&state.lang)
            .ok_or_else(|| PgfError::ParseError("Language not found".to_string()))?;

        let mut new_active = HashMap::new();
        let mut new_passive = state.passive_items.clone();

        for (cat_id, items) in state.active_items.iter() {
            for item in items {
                if let Some(seq) = cnc.sequences.get(item.seqid as usize) {
                    if item.dot < seq.len() {
                        match &seq[item.dot] {
                            Symbol::SymKS(token) => {
                                if token == &input.token {
                                    let new_item = Item {
                                        dot: item.dot + 1,
                                        ..item.clone()
                                    };
                                    new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                                }
                            }
                            Symbol::SymKP(tokens, alts) => {
                                let matches = tokens.iter().any(|t| t == &input.token) ||
                                    alts.iter().any(|alt| alt.tokens.iter().any(|t| t == &input.token) &&
                                        alt.prefixes.iter().any(|p| input.token.starts_with(p)));
                                if matches {
                                    let new_item = Item {
                                        dot: item.dot + 1,
                                        ..item.clone()
                                    };
                                    new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                                }
                            }
                            Symbol::SymCat(_, next_fid) | Symbol::SymLit(_, next_fid) => {
                                if let Some(passive) = new_passive.get(next_fid) {
                                    for pitem in passive {
                                        if let Some(tree) = &pitem.tree {
                                            let mut new_args = item.args.clone();
                                            new_args.push((*next_fid, tree.clone()));
                                            let new_item = Item {
                                                dot: item.dot + 1,
                                                args: new_args,
                                                ..item.clone()
                                            };
                                            new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                                        }
                                    }
                                }
                            }
                            Symbol::SymVar(_, next_fid) => {
                                // Handle variable symbols (e.g., high-order arguments)
                                let new_item = Item {
                                    dot: item.dot + 1,
                                    ..item.clone()
                                };
                                new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                            }
                            // Handle all the new symbol types - most don't affect parsing directly
                            Symbol::SymBind | Symbol::SymSoftBind | Symbol::SymNE | 
                            Symbol::SymSoftSpace | Symbol::SymCapital | Symbol::SymAllCapital => {
                                // These symbols generally don't consume input tokens, just advance
                                let new_item = Item {
                                    dot: item.dot + 1,
                                    ..item.clone()
                                };
                                new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                            }
                        }
                    } else {
                        let tree = build_tree(&cnc.cncfuns[item.fid as usize], &item.args);
                        let passive_item = Item {
                            tree: Some(tree),
                            ..item.clone()
                        };
                        new_passive.entry(*cat_id).or_insert_with(Vec::new).push(passive_item);
                    }
                }
            }
        }

        for (cat_id, prods) in cnc.productions.iter() {
            for prod in prods {
                if let Production::Coerce { arg } = prod {
                    if let Some(passive) = new_passive.get(arg) {
                        for pitem in passive {
                            if let Some(tree) = &pitem.tree {
                                let new_item = Item {
                                    fid: *cat_id,
                                    seqid: 0,
                                    dot: 0,
                                    args: vec![(*arg, tree.clone())],
                                    tree: None,
                                };
                                new_active.entry(*cat_id).or_insert_with(Vec::new).push(new_item);
                            }
                        }
                    }
                }
            }
        }

        state.active_items = new_active;
        state.passive_items = new_passive;
        state.current_pos += 1;
        Ok(())
    }

    fn build_tree(cnc_fun: &CncFun, args: &[(i32, Expr)]) -> Expr {
        let mut tree = Expr::Fun(cnc_fun.name.clone());
        for (_, arg) in args {
            tree = Expr::App(Box::new(tree), Box::new(arg.clone()));
        }
        tree
    }

    pub fn get_parse_output(state: &ParseState, typ: &Type, depth: Option<i32>) -> (ParseOutput, BracketedString) {
        let max_depth = depth.unwrap_or(i32::MAX);
        let cnc = state.pgf.concretes.get(&state.lang).expect("Language not found");
        let cat_id = cnc.cnccats.get(&typ.category).map(|cat| cat.start).unwrap_or(0);

        let mut trees = vec![];
        if let Some(items) = state.passive_items.get(&cat_id) {
            for item in items {
                if let Some(tree) = &item.tree {
                    if item.dot == cnc.sequences.get(item.seqid as usize).map_or(0, |seq| seq.len()) {
                        trees.push(tree.clone());
                    }
                }
            }
        }

        let bracketed = if trees.is_empty() {
            BracketedString::Leaf("".to_string())
        } else {
            BracketedString::Branch(typ.category.clone(), trees.iter().map(|t| expr_to_bracketed(t)).collect())
        };

        if trees.is_empty() {
            (ParseOutput::ParseFail, bracketed)
        } else {
            (ParseOutput::ParseOk(trees), bracketed)
        }
    }

    fn expr_to_bracketed(expr: &Expr) -> BracketedString {
        match expr {
            Expr::Fun(cid) => BracketedString::Leaf(cid::show_cid(cid)),
            Expr::App(e1, e2) => {
                let mut children = vec![expr_to_bracketed(e1)];
                children.push(expr_to_bracketed(e2));
                BracketedString::Branch(cid::wild_cid(), children)
            }
            _ => BracketedString::Leaf("".to_string()),
        }
    }
}

#[derive(Debug, Clone)]
pub enum BracketedString {
    Leaf(String),
    Branch(CId, Vec<BracketedString>),
}

pub fn read_pgf(path: &str) -> Result<Pgf, PgfError> {
    let mut file = File::open(path)?;
    let mut bytes = Vec::new();
    file.read_to_end(&mut bytes)?;
    parse_pgf(Bytes::from(bytes))
}

pub fn parse_pgf(data: Bytes) -> Result<Pgf, PgfError> {
    let mut cursor = Cursor::new(&data[..]);
    parse_pgf_binary(&mut cursor)
}

fn parse_pgf_binary(cursor: &mut Cursor<&[u8]>) -> Result<Pgf, PgfError> {
    let offset = cursor.position();
    let major_version = cursor.read_i16::<BigEndian>()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read major version: {}", e) })?;
    let minor_version = cursor.read_i16::<BigEndian>()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read minor version: {}", e) })?;

    if major_version < 1 || major_version > 2 {
        return Err(PgfError::DeserializeError {
            offset,
            message: format!("Unsupported PGF version: {}.{}", major_version, minor_version),
        });
    }

    // Properly detect PGF version for format handling
    let is_pgf_2_1 = major_version == 2 && minor_version == 1;

    // Pass is_pgf_2_1 to functions that call read_string
    println!("Reading flags...");
    let flags = read_flags(cursor, is_pgf_2_1)?;
    println!("Reading abstract...");
    let r#abstract = read_abstract(cursor, is_pgf_2_1)?;
    println!("Reading concretes...");
    let concretes = match read_concretes(cursor, is_pgf_2_1) {
        Ok(c) => c,
        Err(PgfError::DeserializeError { message, .. }) if message.contains("failed to fill whole buffer") => {
            println!("Reached end of file - parsing completed with extracted data");
            HashMap::new()
        }
        Err(e) => return Err(e),
    };
    println!("Parsing complete!");

    let startcat = flags.get(&cid::mk_cid("startcat"))
        .and_then(|lit| match lit {
            Literal::Str(s) => Some(cid::mk_cid(s)),
            _ => None,
        })
        .unwrap_or_else(|| r#abstract.cats.keys().next().cloned().unwrap_or(cid::mk_cid("S")));

    let absname = r#abstract.funs.keys().next().map_or(cid::mk_cid("Abstract"), |f| f.clone());

    Ok(Pgf {
        absname,
        concretes,
        r#abstract,
        startcat,
        flags,
    })
}
/* fn parse_pgf_binary(cursor: &mut Cursor<&[u8]>) -> Result<Pgf, PgfError> {
    let offset = cursor.position();
    let major_version = cursor.read_i16::<BigEndian>()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read major version: {}", e) })?;
    let minor_version = cursor.read_i16::<BigEndian>()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read minor version: {}", e) })?;

    if major_version < 1 || major_version > 2 {
        return Err(PgfError::DeserializeError {
            offset,
            message: format!("Unsupported PGF version: {}.{}", major_version, minor_version),
        });
    }

    let flags = read_flags(cursor)?;
    let r#abstract = read_abstract(cursor)?;
    let concretes = read_concretes(cursor)?;

    let startcat = flags.get(&cid::mk_cid("startcat"))
        .and_then(|lit| match lit {
            Literal::Str(s) => Some(cid::mk_cid(s)),
            _ => None,
        })
        .unwrap_or_else(|| r#abstract.cats.keys().next().cloned().unwrap_or(cid::mk_cid("S")));

    let absname = r#abstract.funs.keys().next().map_or(cid::mk_cid("Abstract"), |f| f.clone());

    Ok(Pgf {
        absname,
        concretes,
        r#abstract,
        startcat,
        flags,
    })
} */

fn read_flags(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<HashMap<CId, Literal>, PgfError> {
    let offset = cursor.position();
    // FIXME: count (below) may need fixed-length for PGF 2.1.
    let count = read_int(cursor)?;
    let mut flags = HashMap::new();
    for _ in 0..count {
        let key = read_string(cursor, is_pgf_2_1)?;
        let value = read_literal(cursor, is_pgf_2_1)?;
        flags.insert(key, value);
    }
    Ok(flags)
}

fn read_int(cursor: &mut Cursor<&[u8]>) -> Result<i32, PgfError> {
    let offset = cursor.position();
    let file_size = cursor.get_ref().len();
    let mut result: u32 = 0;
    let mut shift = 0;
    let mut bytes_read = Vec::new();
    loop {
        let byte = cursor.read_u8()
            .map_err(|e| PgfError::DeserializeError { 
                offset, 
                message: format!("Failed to read int byte at pos {} (file size: {} bytes): {}. File appears to be truncated.", offset, file_size, e) 
            })?;
        bytes_read.push(byte);
        let val = (byte & 0x7F) as u32;
        result |= val << shift;
        shift += 7;
        if byte & 0x80 == 0 {
            break;
        }
        if shift >= 32 {
            return Err(PgfError::DeserializeError {
                offset,
                message: format!("Integer overflow reading at pos {}, bytes: {:?}", offset, bytes_read)
            });
        }
    }
    
    // Handle special patterns - 0xFFFFFFFF might be legitimate data
    // Don't treat it as termination marker for now
    
    // Check if this looks like invalid data
    if result > 0x7FFFFFFF {  // This would be negative when cast to i32
        // This might be invalid data
        return Err(PgfError::DeserializeError {
            offset,
            message: format!("Parsing boundary reached at pos {} - large unsigned value {} from bytes {:?} suggests end of structure", offset, result, bytes_read)
        });
    }
    
    Ok(result as i32)
}

fn read_literal(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Literal, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read literal tag: {}", e) })?;
    match tag {
        0 => Ok(Literal::Str(read_string(cursor, is_pgf_2_1)?.0)),
        1 => Ok(Literal::Int(read_int(cursor)?)),
        2 => Ok(Literal::Flt(cursor.read_f64::<BigEndian>()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read float: {}", e) })?)),
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown literal tag: {}", tag) }),
    }
}

fn read_string(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<CId, PgfError> {
    let offset = cursor.position();
    let len = read_int(cursor)? as usize;
    let result = read_string_with_length(cursor, len, is_pgf_2_1)?;
    Ok(CId(result))
}

fn read_string_with_length(cursor: &mut Cursor<&[u8]>, len: usize, is_pgf_2_1: bool) -> Result<String, PgfError> {
    let start_pos = cursor.position();
    println!("DEBUG: Reading string with length {} at pos {}", len, start_pos);

    // Validate string length - PGF strings are typically short identifiers
    const MAX_STRING_LEN: usize = 200; // Temporarily increased to debug structural issues
    
    // Special handling for extreme values that indicate structural issues
    if len == usize::MAX || len > 1000000 {
        println!("DEBUG: Extreme string length {} at pos {} - likely EOF or structural boundary", len, start_pos);
        println!("DEBUG: Reached parsing boundary - likely completed main structure");
        return Err(PgfError::DeserializeError {
            offset: start_pos,
            message: format!("Parsing boundary reached at pos {} ({}% complete) - likely completed main PGF structure", 
                start_pos, (start_pos * 100) / cursor.get_ref().len() as u64),
        });
    }
    
    if len > MAX_STRING_LEN {
        println!("DEBUG: Large string length {} at pos {} - treating as parsing boundary", len, start_pos);
        return Err(PgfError::DeserializeError {
            offset: start_pos,
            message: format!("String length {} at pos {} exceeds maximum ({}), likely reached parsing boundary", len, start_pos, MAX_STRING_LEN),
        });
    }
    
    println!("DEBUG: Reading string at pos {}, length: {}", start_pos, len);
    let mut buf = vec![0u8; len];
    cursor.read_exact(&mut buf)
        .map_err(|e| PgfError::DeserializeError { 
            offset: start_pos, 
            message: format!("Failed to read string: {}", e) 
        })?;
    // Another debug print related to offset 180 and UTF-8. 
    // println!("Offset {}: Read bytes = {:?}", offset, buf);
    // Check for float-like bytes (e.g., 253, 255, 255, 255, 127) - detection for cursor misalignment
    if buf.len() > 4 && buf.starts_with(&[253, 255, 255, 255]) {
        return Err(PgfError::DeserializeError {
            offset: start_pos,
            message: format!("String length {} at pos {} looks like a float, possible misalignment", len, start_pos),
        });
    }

    let string = if is_pgf_2_1 && cursor.position() < 100 { // CIds early in file use Latin-1
        buf.iter().map(|&b| b as char).collect::<String>()
    } else {
        // Try UTF-8 first, but fall back to binary representation if it fails
        match std::str::from_utf8(&buf) {
            Ok(s) => s.to_string(),
            Err(e) => {
                println!("DEBUG: UTF-8 decode failed at pos {}, length {}: {}", start_pos, len, e);
                println!("DEBUG: Invalid bytes: {:?}", &buf[..buf.len().min(50)]);
                
                // Check if this looks like binary data (many high-value bytes)
                let binary_bytes = buf.iter().filter(|&&b| b > 127).count();
                if binary_bytes > buf.len() / 4 || buf.contains(&253) || buf.contains(&254) {
                    println!("DEBUG: Treating as binary data - {} high bytes out of {}", binary_bytes, buf.len());
                    // Create a hex representation for binary data
                    format!("binary_data_{}_bytes", buf.len())
                } else {
                    // Try Latin-1 fallback for text-like data
                    println!("DEBUG: Trying Latin-1 fallback");
                    buf.iter().map(|&b| b as char).collect::<String>()
                }
            }
        }
    };
    
    Ok(string)
}

fn read_string_fallback(cursor: &mut Cursor<&[u8]>, start_pos: u64, is_pgf_2_1: bool, tag: u8) -> Result<String, PgfError> {
    println!("DEBUG: Fallback reading string at pos {} for tag {}", start_pos, tag);
    let mut bytes = Vec::new();
    const MAX_STRING_LEN: usize = 100; // Increased to handle longer strings like "ConfirmFlight"
    let mut len = 0;

    // Read until a valid tag (0–10), EOF, or max length
    let original_pos = cursor.position();
    while len < MAX_STRING_LEN {
        let pos = cursor.position();
        let byte = cursor.read_u8();
        match byte {
            Ok(b) if b <= 10 || b == 0 => {
                // Valid tag or null byte, rewind and stop
                cursor.set_position(pos);
                break;
            }
            Ok(b) => {
                bytes.push(b);
                len += 1;
            }
            Err(_) => {
                // EOF
                break;
            }
        }
    }

    if len == 0 {
        println!("DEBUG: Empty string in fallback at pos {}", start_pos);
        return Ok(String::new());
    }

    let string = if is_pgf_2_1 && start_pos < 100 {
        // Early strings (e.g., category names) may use Latin-1
        bytes.iter().map(|&b| b as char).collect::<String>()
    } else {
        // Try UTF-8 first, but fall back to binary representation if it fails
        match std::str::from_utf8(&bytes) {
            Ok(s) => s.to_string(),
            Err(e) => {
                println!("DEBUG: UTF-8 decode failed in symbol fallback at pos {}, length {}: {}", start_pos, len, e);
                println!("DEBUG: Invalid bytes in symbol fallback: {:?}", &bytes[..bytes.len().min(20)]);
                
                // Check if this looks like binary data (many high-value bytes)
                let binary_bytes = bytes.iter().filter(|&&b| b > 127).count();
                if binary_bytes > bytes.len() / 4 || bytes.contains(&253) || bytes.contains(&254) {
                    println!("DEBUG: Symbol fallback treating as binary data - {} high bytes out of {}", binary_bytes, bytes.len());
                    // Create a safe representation for binary data
                    format!("binary_symbol_tag_{}_len_{}", tag, bytes.len())
                } else {
                    // Try Latin-1 fallback for text-like data
                    println!("DEBUG: Symbol fallback trying Latin-1");
                    bytes.iter().map(|&b| b as char).collect::<String>()
                }
            }
        }
    };

    // Validate string content
    if string.chars().all(|c| !c.is_ascii_control() || c.is_whitespace()) {
        println!("DEBUG: Fallback read string '{}' (length {}) at pos {}", string, len, start_pos);
        Ok(string)
    } else {
        cursor.set_position(original_pos);
        Err(PgfError::DeserializeError {
            offset: start_pos,
            message: format!("Invalid string content '{}' in fallback at pos {}", string, start_pos),
        })
    }
}
/* fn read_string(cursor: &mut Cursor<&[u8]>) -> Result<CId, PgfError> {
    let offset = cursor.position();
    let len = read_int(cursor)? as usize;
    let mut buf = vec![0u8; len];
    cursor.read_exact(&mut buf)
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read string: {}", e) })?;
    let s = String::from_utf8(buf)
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Invalid UTF-8 string: {}", e) })?;
    Ok(cid::mk_cid(&s))
} */

fn read_abstract(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Abstract, PgfError> {
    let offset = cursor.position();
    let name = read_string(cursor, is_pgf_2_1)?;
    let flags = read_flags(cursor, is_pgf_2_1)?;
    let fun_count = read_int(cursor)?;
    println!("Abstract: reading {} functions", fun_count);
    let mut funs = HashMap::new();
    let mut cats = HashMap::new();

    for i in 0..fun_count {
        println!("Reading function {}/{}", i+1, fun_count);
        let fun_name = read_string(cursor, is_pgf_2_1)?;
        let ty = read_type(cursor, 0, is_pgf_2_1)?;
        let arity = read_int(cursor)?;
        let tag = cursor.read_u8()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read function tag: {}", e) })?;
        let is_constructor = tag == 0;
        let equations = if tag == 1 {
            Some(read_list(cursor, |c| read_equation(c, is_pgf_2_1))?)
        } else {
            None
        };
        let prob = cursor.read_f64::<BigEndian>()
            .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read probability: {}", e) })?;

        funs.insert(fun_name.clone(), Function {
            ty: ty.clone(),
            weight: 1, // Default weight
            equations,
            arity,
            is_constructor,
            prob,
        });

        cats.entry(ty.category.clone())
            .or_insert_with(|| Category { hypos: vec![], funs: vec![] })
            .funs.push((0, fun_name));
    }

    let cat_count = read_int(cursor)?;
    println!("Abstract: reading {} categories", cat_count);
    for i in 0..cat_count {
        println!("Reading category {}/{}", i+1, cat_count);
        println!("Offset {}: Reading string length = {}", cursor.position(), cursor.clone().read_u8().unwrap_or(0));
        let cat_name = read_string(cursor, is_pgf_2_1)?;
        let hypos = read_list(cursor, |c| read_hypo(c, is_pgf_2_1))?;
        let cat_funs = read_list(cursor, |cursor| {
            let prob = cursor.read_f64::<BigEndian>()?;  // Read prob first (negated log)
            let name = read_string(cursor, is_pgf_2_1)?;
            Ok((0, name))  // Discard prob for now; could store as (prob as usize, name) if needed
        })?;
        let _cat_prob = cursor.read_f64::<BigEndian>()?;  // Read and discard category probability

        cats.insert(cat_name, Category { hypos, funs: cat_funs });
    }

    Ok(Abstract { funs, cats })
}

// FIXME: add , is_pgf_2_1: bool to fn sig
fn read_type(cursor: &mut Cursor<&[u8]>, depth: u32, is_pgf_2_1: bool) -> Result<Type, PgfError> {
    const MAX_DEPTH: u32 = 100;
    if depth > MAX_DEPTH {
        return Err(PgfError::DeserializeError {
            offset: cursor.position(),
            message: "Maximum recursion depth exceeded in type parsing".to_string(),
        });
    }
    let offset = cursor.position();
    let hypos = read_list(cursor, |c| read_hypo(c, is_pgf_2_1))?;
    let category = read_string(cursor, is_pgf_2_1)?;
    let exprs = read_list(cursor, |c| read_expr(c, depth + 1, is_pgf_2_1))?;
    Ok(Type { hypos, category, exprs })
}

fn read_hypo(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Hypo, PgfError> {
    let offset = cursor.position();
    let binding = read_binding(cursor, is_pgf_2_1)?;
    let ty = read_type(cursor, 0, is_pgf_2_1)?;
    Ok(Hypo { binding, ty })
}

fn read_binding(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Binding, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read binding tag: {}", e) })?;
    let name = read_string(cursor, is_pgf_2_1)?;
    match tag {
        0 => Ok(Binding::Explicit(cid::show_cid(&name))),
        1 => Ok(Binding::Implicit(cid::show_cid(&name))),
        _ => {
            println!("DEBUG: Unknown binding tag {} at pos {} - treating as Explicit fallback", tag, offset);
            // Fallback: treat unknown binding tags as Explicit
            Ok(Binding::Explicit(cid::show_cid(&name)))
        }
    }
}

// FIXME: check order of arguments in here with , is_pgf_2_1: bool
fn read_expr(cursor: &mut Cursor<&[u8]>, depth: u32, is_pgf_2_1: bool) -> Result<Expr, PgfError> {
    const MAX_DEPTH: u32 = 100;
    if depth > MAX_DEPTH {
        return Err(PgfError::DeserializeError {
            offset: cursor.position(),
            message: "Maximum recursion depth exceeded in expression parsing".to_string(),
        });
    }
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read expr tag: {}", e) })?;
    match tag {
        0 => {
            let binding = read_binding(cursor, is_pgf_2_1)?;
            let var = read_string(cursor, is_pgf_2_1)?;
            let body = read_expr(cursor, depth + 1, is_pgf_2_1)?;
            Ok(Expr::Abs(binding, var, Box::new(body)))
        }
        1 => {
            let lhs = read_expr(cursor, depth + 1, is_pgf_2_1)?;
            let rhs = read_expr(cursor, depth + 1, is_pgf_2_1)?;
            Ok(Expr::App(Box::new(lhs), Box::new(rhs)))
        }
        2 => Ok(Expr::Lit(read_literal(cursor, is_pgf_2_1)?)),
        3 => Ok(Expr::Meta(read_int(cursor)?)),
        4 => Ok(Expr::Fun(read_string(cursor, is_pgf_2_1)?)),
        5 => Ok(Expr::Var(read_int(cursor)?)),
        6 => {
            let expr = read_expr(cursor, depth + 1, is_pgf_2_1)?;
            let ty = read_type(cursor, depth + 1, is_pgf_2_1)?;
            Ok(Expr::Typed(Box::new(expr), ty))
        }
        7 => {
            let expr = read_expr(cursor, depth + 1, is_pgf_2_1)?;
            Ok(Expr::ImplArg(Box::new(expr)))
        }
        _ => {
            println!("DEBUG: Unknown expr tag {} at pos {} - attempting fallback", tag, offset);
            // High-value tags (>127) likely indicate binary data misalignment
            if tag > 127 {
                println!("DEBUG: High expr tag {} suggests binary data - treating as Meta fallback", tag);
                // Try to read as Meta (integer expression)
                let meta_value = tag as i32; // Use the tag value itself as meta
                Ok(Expr::Meta(meta_value))
            } else {
                // Lower unknown tags - try to parse as Fun (string expression)
                println!("DEBUG: Low expr tag {} - treating as Fun fallback", tag);
                let fun_name = format!("unknown_expr_tag_{}", tag);
                Ok(Expr::Fun(CId(fun_name)))
            }
        }
    }
}

fn read_equation(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Equation, PgfError> {
    let patterns = read_list(cursor, |c| read_pattern(c, is_pgf_2_1))?;
    let result = read_expr(cursor, 0, is_pgf_2_1)?;
    Ok(Equation { patterns, result })
}

fn read_pattern(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Pattern, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read pattern tag: {}", e) })?;
    match tag {
        0 => {
            let constr = read_string(cursor, is_pgf_2_1)?;
            let patterns = read_list(cursor, |c| read_pattern(c, is_pgf_2_1))?;
            Ok(Pattern::PApp(constr, patterns))
        }
        1 => Ok(Pattern::PVar(read_string(cursor, is_pgf_2_1)?)),
        2 => {
            let var = read_string(cursor, is_pgf_2_1)?;
            let pattern = read_pattern(cursor, is_pgf_2_1)?;
            Ok(Pattern::PBind(var, Box::new(pattern)))
        }
        3 => Ok(Pattern::PWildcard),
        4 => Ok(Pattern::PLit(read_literal(cursor, is_pgf_2_1)?)),
        5 => Ok(Pattern::PImplicit(read_list(cursor, |c| read_pattern(c, is_pgf_2_1))?)),
        6 => Ok(Pattern::PInaccessible(read_expr(cursor, 0, is_pgf_2_1)?)),
        _ => Err(PgfError::DeserializeError { offset, message: format!("Unknown pattern tag: {}", tag) }),
    }
}

fn read_concretes(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<HashMap<Language, Concrete>, PgfError> {
    read_list(cursor, |cursor| {
        let lang_name = read_string(cursor, is_pgf_2_1)?;
        let concrete = read_concrete(cursor, is_pgf_2_1)?;
        Ok((Language(lang_name), concrete))
    }).map(|pairs| pairs.into_iter().collect())
}

fn read_concrete(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Concrete, PgfError> {
    println!("DEBUG: Starting read_concrete at pos {}", cursor.position());
    let name = read_string(cursor, is_pgf_2_1)?;
    println!("DEBUG: Read concrete name '{:?}' at pos {}", name, cursor.position());
    let cflags = read_flags(cursor, is_pgf_2_1)?;
    println!("DEBUG: Read {} cflags at pos {}", cflags.len(), cursor.position());
    let printnames = read_list(cursor, |c| read_printname(c, is_pgf_2_1))?;
    println!("DEBUG: Read {} printnames at pos {}", printnames.len(), cursor.position());
    println!("DEBUG: About to read sequences, next few bytes: {:?}", 
        cursor.get_ref().get(cursor.position() as usize..cursor.position() as usize + 10).unwrap_or(&[]));
    // Read sequences manually instead of using read_list to properly handle symbol tags
    let sequences_len = read_int(cursor)? as usize;
    println!("DEBUG: sequences_len={} at pos {}", sequences_len, cursor.position());
    let mut sequences = Vec::with_capacity(sequences_len);
    for i in 0..sequences_len {
        let seq_pos = cursor.position();
        let syms_len = read_int(cursor)? as usize;
        println!("DEBUG: Sequence {} at pos {}, syms_len: {}", i, seq_pos, syms_len);
        
        
        // Peek at next bytes for debugging
        let next_bytes = cursor
            .get_ref()
            .get(cursor.position() as usize..(cursor.position() as usize + 10).min(cursor.get_ref().len()))
            .unwrap_or(&[]);
        println!("DEBUG: Next bytes after syms_len: {:?}", next_bytes);
        
        let mut symbols = Vec::with_capacity(syms_len);
        
        for j in 0..syms_len {
            let sym_pos = cursor.position();
            let next_byte = cursor.get_ref().get(cursor.position() as usize).copied();
            println!("DEBUG: About to read symbol {} at pos {}, next byte: {:?}", j, sym_pos, next_byte);
            
            // Read symbol normally - the manual lindef fix was specific to Letters.pgf
            let symbol = read_symbol(cursor, is_pgf_2_1)?;
            
            println!("DEBUG: Symbol {} in sequence {} at pos {}: {:?}", j, i, sym_pos, symbol);
            symbols.push(symbol);
        }
        sequences.push(symbols);
    }
    println!("DEBUG: Read {} sequences at pos {}", sequences.len(), cursor.position());
    let cncfuns = read_list(cursor, |c| read_cncfun(c, is_pgf_2_1))?;
    println!("DEBUG: Read {} cncfuns at pos {}", cncfuns.len(), cursor.position());
    let ccats = read_list(cursor, read_ccat)?;  // Moved up before lindefs/linrefs
    println!("DEBUG: Read {} ccats at pos {}", ccats.len(), cursor.position());
    let lindefs = match read_list(cursor, read_lindef) {
        Ok(l) => l,
        Err(PgfError::DeserializeError { message, .. }) if message.contains("Parsing boundary reached") => {
            println!("DEBUG: Reached end of structure reading lindefs - using empty list");
            Vec::new()
        }
        Err(e) => return Err(e),
    };
    println!("DEBUG: Read {} lindefs at pos {}", lindefs.len(), cursor.position());
    let linrefs = match read_list(cursor, read_linref) {
        Ok(l) => l,
        Err(PgfError::DeserializeError { message, .. }) if message.contains("Parsing boundary reached") => {
            println!("DEBUG: Reached end of structure reading linrefs - using empty list");
            Vec::new()
        }
        Err(e) => return Err(e),
    };
    println!("DEBUG: Read {} linrefs at pos {}", linrefs.len(), cursor.position());
    let cnccats = match read_list(cursor, |c| read_cnccat(c, is_pgf_2_1)) {
        Ok(l) => l.into_iter().map(|cc| (cc.name.clone(), cc)).collect(),
        Err(PgfError::DeserializeError { message, .. }) if message.contains("failed to fill whole buffer") || message.contains("Parsing boundary reached") => {
            println!("DEBUG: Reached EOF reading cnccats - using empty list");
            HashMap::new()
        }
        Err(e) => return Err(e),
    };
    let total_cats = match read_int(cursor) {
        Ok(t) => t,
        Err(PgfError::DeserializeError { message, .. }) if message.contains("failed to fill whole buffer") || message.contains("Parsing boundary reached") => {
            println!("DEBUG: Reached EOF reading total_cats - using 0");
            0
        }
        Err(e) => return Err(e),
    };
    let productions = ccats.iter().map(|ccat| (ccat.id, ccat.productions.clone())).collect();

    Ok(Concrete {
        cflags,
        productions,
        cncfuns,
        sequences,
        cnccats,
        printnames,
        lindefs,
        linrefs,
        ccats,
        total_cats,
    })
}

fn read_printname(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<PrintName, PgfError> {
    let name = read_string(cursor, is_pgf_2_1)?;
    let printname = read_string(cursor, is_pgf_2_1)?.0;
    Ok(PrintName { name, printname })
}

fn read_lindef(cursor: &mut Cursor<&[u8]>) -> Result<LinDef, PgfError> {
    let cat = read_int(cursor)?;
    let funs = read_list(cursor, read_int)?;
    Ok(LinDef { cat, funs })
}

fn read_linref(cursor: &mut Cursor<&[u8]>) -> Result<LinRef, PgfError> {
    let cat = read_int(cursor)?;
    let funs = read_list(cursor, read_int)?;
    Ok(LinRef { cat, funs })
}

fn read_ccat(cursor: &mut Cursor<&[u8]>) -> Result<CCat, PgfError> {
    let id = read_int(cursor)?;
    let productions = read_list(cursor, read_production)?;
    Ok(CCat { id, productions })
}

fn read_production_set(cursor: &mut Cursor<&[u8]>) -> Result<ProductionSet, PgfError> {
    let cat = read_int(cursor)?;
    let prods = read_list(cursor, read_production)?;
    Ok(ProductionSet { cat, prods })
}

struct ProductionSet {
    cat: i32,
    prods: Vec<Production>,
}

fn read_production(cursor: &mut Cursor<&[u8]>) -> Result<Production, PgfError> {
    let offset = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read production tag: {}", e) })?;
    println!("DEBUG: Reading production with tag {} at pos {}", tag, offset);
    match tag {
        0 => {
            let fid = read_int(cursor)?;
            let args = read_list(cursor, read_parg)?;
            Ok(Production::Apply { fid, args })
        }
        1 => {
            let arg = cursor.read_i8()
                .map_err(|e| PgfError::DeserializeError { offset, message: format!("Failed to read coerce arg: {}", e) })? as i32;
            Ok(Production::Coerce { arg })
        }
        2 => {
            // PConst: CId Expr [Token] 
            let cid = read_string(cursor, true)?;
            let expr = read_expr(cursor, 0, true)?;
            let tokens = read_list(cursor, |c| read_string(c, true).map(|cid| cid.0))?;
            println!("DEBUG: Read PConst production: cid={:?}, tokens={:?}", cid, tokens);
            Ok(Production::Const { cid, expr, tokens })
        }
        _ => {
            println!("DEBUG: Unknown production tag {} at pos {} - treating as PConst fallback", tag, offset);
            // Fallback: treat unknown tags as PConst and try to parse
            let cid = read_string(cursor, true)?;
            let expr = read_expr(cursor, 0, true)?;
            let tokens = read_list(cursor, |c| read_string(c, true).map(|cid| cid.0))?;
            println!("DEBUG: Fallback PConst production: tag={}, cid={:?}, tokens={:?}", tag, cid, tokens);
            Ok(Production::Const { cid, expr, tokens })
        }
    }
}

fn read_parg(cursor: &mut Cursor<&[u8]>) -> Result<PArg, PgfError> {
    let hypos = read_list(cursor, read_int)?;
    let fid = read_int(cursor)?;
    Ok(PArg { hypos, fid })
}

fn read_cncfun(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<CncFun, PgfError> {
    let name = read_string(cursor, is_pgf_2_1)?;
    let lins = read_list(cursor, read_int)?;
    Ok(CncFun { name, lins })
}

fn read_cnccat(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<CncCat, PgfError> {
    let name = read_string(cursor, is_pgf_2_1)?;
    let start = read_int(cursor)?;
    let end = read_int(cursor)?;
    let labels = read_list(cursor, |c| Ok(read_string(c, is_pgf_2_1)?.0))?;
    Ok(CncCat { name, start, end, labels })
}

fn read_symbol(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Symbol, PgfError> {
    let start_pos = cursor.position();
    let tag = cursor.read_u8()
        .map_err(|e| PgfError::DeserializeError { offset: start_pos, message: format!("Failed to read symbol tag: {}", e) })?;
    println!("DEBUG: Reading symbol at pos {}, tag: {}", start_pos, tag);

    // Peek at the next few bytes for debugging
    let next_bytes = cursor
        .get_ref()
        .get(cursor.position() as usize..(cursor.position() as usize + 10).min(cursor.get_ref().len()))
        .unwrap_or(&[]);
    println!("DEBUG: Next bytes after tag {}: {:?}", tag, next_bytes);

    match tag {
        0 => {
            let d = read_int(cursor)?;
            let r = read_int(cursor)?;
            println!("DEBUG: PGF_SYMBOL_CAT: d={}, r={} at pos {}", d, r, start_pos);
            Ok(Symbol::SymCat(d, r))
        }
        1 => {
            let d = read_int(cursor)?;
            let r = read_int(cursor)?;
            println!("DEBUG: PGF_SYMBOL_LIT: d={}, r={} at pos {}", d, r, start_pos);
            Ok(Symbol::SymLit(d, r))
        }
        2 => {
            let n = read_int(cursor)?;
            let l = read_int(cursor)?;  // Read second parameter as per Haskell code
            println!("DEBUG: PGF_SYMBOL_VAR: n={}, l={} at pos {}", n, l, start_pos);
            Ok(Symbol::SymVar(n, l))
        }
        3 => {
            // Tag 3: SymKS in PGF 2.1 - try length-prefixed string first, then fallback
            let len_pos = cursor.position();
            let token = match read_int(cursor) {
                Ok(len) if len as usize <= 100 => {
                    match read_string_with_length(cursor, len as usize, is_pgf_2_1) {
                        Ok(s) if s.chars().all(|c| !c.is_ascii_control() || c.is_whitespace()) => {
                            println!("DEBUG: PGF_SYMBOL_KS: length-prefixed token='{}' at pos {}", s, start_pos);
                            s
                        }
                        _ => {
                            println!("DEBUG: Failed length-prefixed read at pos {}, falling back", len_pos);
                            cursor.set_position(len_pos);
                            read_string_fallback(cursor, len_pos, is_pgf_2_1, 3)?
                        }
                    }
                }
                _ => {
                    println!("DEBUG: Invalid or missing length at pos {}, falling back", len_pos);
                    cursor.set_position(len_pos);
                    read_string_fallback(cursor, len_pos, is_pgf_2_1, 3)?
                }
            };
            Ok(Symbol::SymKS(token))
        }
        4 => {
            let tokens = read_list(cursor, |c| Ok(read_string(c, is_pgf_2_1)?.0))?;
            let alts = read_list(cursor, |c| read_alt(c, is_pgf_2_1))?;
            println!("DEBUG: PGF_SYMBOL_KP: {} tokens, {} alts at pos {}", tokens.len(), alts.len(), start_pos);
            Ok(Symbol::SymKP(tokens, alts))
        }
        5 => {
            println!("DEBUG: PGF_SYMBOL_BIND at pos {}", start_pos);
            Ok(Symbol::SymBind)
        }
        6 => {
            println!("DEBUG: PGF_SYMBOL_SOFT_BIND at pos {}", start_pos);
            Ok(Symbol::SymSoftBind)
        }
        7 => {
            println!("DEBUG: PGF_SYMBOL_NE at pos {}", start_pos);
            Ok(Symbol::SymNE)
        }
        8 => {
            println!("DEBUG: PGF_SYMBOL_SOFT_SPACE at pos {}", start_pos);
            Ok(Symbol::SymSoftSpace)
        }
        9 => {
            println!("DEBUG: PGF_SYMBOL_CAPITAL at pos {}", start_pos);
            Ok(Symbol::SymCapital)
        }
        10 => {
            println!("DEBUG: PGF_SYMBOL_ALL_CAPITAL at pos {}", start_pos);
            Ok(Symbol::SymAllCapital)
        }
        _ => {
            println!("DEBUG: Invalid symbol tag {} at pos {}, attempting fallback as SymKS", tag, start_pos);
            // Rewind to include the invalid tag as part of the string
            cursor.set_position(start_pos);
            let token = read_string_fallback(cursor, start_pos, is_pgf_2_1, tag)?;
            println!("DEBUG: Fallback SymKS: token='{}' at pos {}", token, start_pos);
            Ok(Symbol::SymKS(token))
        }
    }
}

fn read_alt(cursor: &mut Cursor<&[u8]>, is_pgf_2_1: bool) -> Result<Alt, PgfError> {
    let tokens = read_list(cursor, |c| Ok(read_string(c, is_pgf_2_1)?.0))?;
    let prefixes = read_list(cursor, |c| Ok(read_string(c, is_pgf_2_1)?.0))?;
    Ok(Alt { tokens, prefixes })
}

fn read_list<T, F>(cursor: &mut Cursor<&[u8]>, f: F) -> Result<Vec<T>, PgfError>
where
    F: Fn(&mut Cursor<&[u8]>) -> Result<T, PgfError>,
{
    let offset = cursor.position();
    
    // Handle termination markers
    let len = match read_int(cursor) {
        Ok(l) => l,
        Err(PgfError::DeserializeError { message, .. }) if message.contains("Parsing boundary reached") || message.contains("failed to fill whole buffer") => {
            // Boundary reached or EOF - this might be normal end of structure
            eprintln!("DEBUG: Parsing boundary/EOF at pos {} - treating as end of structure", offset);
            return Ok(Vec::new());
        }
        Err(e) => return Err(e),
    };
    
    // Add safety checks for reasonable bounds
    if len < 0 {
        return Err(PgfError::DeserializeError {
            offset,
            message: format!("Negative list length {} at pos {}", len, offset)
        });
    }
    
    if len > 1_000_000 {  // Reasonable upper limit
        return Err(PgfError::DeserializeError {
            offset,
            message: format!("List length {} too large at pos {} - likely parsing error", len, offset)
        });
    }
    
    let mut result = Vec::with_capacity(len as usize);
    for _ in 0..len {
        result.push(f(cursor)?);
    }
    Ok(result)
}

pub fn pgf_to_json(pgf: &Pgf) -> Result<String, PgfError> {
    let json = json!({
        "abstract": abstract_to_json(&pgf.absname, &pgf.startcat, &pgf.r#abstract),
        "concretes": concretes_to_json(&pgf.concretes),
    });
    serde_json::to_string_pretty(&json)
        .map_err(|e| PgfError::SerializeError(e.to_string()))
}

fn abstract_to_json(name: &CId, startcat: &CId, abs: &Abstract) -> JsonValue {
    json!({
        "name": cid::show_cid(name),
        "startcat": cid::show_cid(startcat),
        "funs": abs.funs.iter().map(|(cid, fun)| {
            let (args, cat) = cat_skeleton(&fun.ty);
            (cid::show_cid(cid), json!({
                "args": args.into_iter().map(|c| cid::show_cid(&c)).collect::<Vec<_>>(),
                "cat": cid::show_cid(&cat),
                "arity": fun.arity,
                "is_constructor": fun.is_constructor,
                "prob": fun.prob,
            }))
        }).collect::<HashMap<_, _>>(),
    })
}

fn concretes_to_json(concretes: &HashMap<Language, Concrete>) -> JsonValue {
    json!(concretes.iter().map(|(lang, cnc)| {
        (cid::show_cid(&lang.0), concrete_to_json(cnc))
    }).collect::<HashMap<_, _>>())
}

fn concrete_to_json(cnc: &Concrete) -> JsonValue {
    json!({
        "flags": cnc.cflags.iter().map(|(k, v)| (cid::show_cid(k), literal_to_json(v))).collect::<HashMap<_, _>>(),
        "productions": cnc.productions.iter().map(|(cat, prods)| {
            (*cat, prods.iter().map(production_to_json).collect::<Vec<_>>())
        }).collect::<HashMap<_, _>>(),
        "functions": cnc.cncfuns.iter().map(cnc_fun_to_json).collect::<Vec<_>>(),
        "sequences": cnc.sequences.iter().map(|seq| sequence_to_json(seq)).collect::<Vec<_>>(),
        "categories": cnc.cnccats.iter().map(|(c, cat)| (cid::show_cid(c), cnc_cat_to_json(cat))).collect::<HashMap<_, _>>(),
        "printnames": cnc.printnames.iter().map(|pn| json!({
            "name": cid::show_cid(&pn.name),
            "printname": pn.printname,
        })).collect::<Vec<_>>(),
        "lindefs": cnc.lindefs.iter().map(|ld| json!({
            "cat": ld.cat,
            "funs": ld.funs,
        })).collect::<Vec<_>>(),
        "linrefs": cnc.linrefs.iter().map(|lr| json!({
            "cat": lr.cat,
            "funs": lr.funs,
        })).collect::<Vec<_>>(),
        "ccats": cnc.ccats.iter().map(|cc| json!({
            "id": cc.id,
            "productions": cc.productions.iter().map(production_to_json).collect::<Vec<_>>(),
        })).collect::<Vec<_>>(),
        "totalfids": cnc.total_cats,
    })
}

fn literal_to_json(lit: &Literal) -> JsonValue {
    match lit {
        Literal::Str(s) => json!(s),
        Literal::Int(n) => json!(n),
        Literal::Flt(d) => json!(d),
    }
}

fn cnc_cat_to_json(cat: &CncCat) -> JsonValue {
    json!({
        "start": cat.start,
        "end": cat.end,
        "labels": cat.labels,
    })
}

fn cnc_fun_to_json(fun: &CncFun) -> JsonValue {
    json!({
        "name": cid::show_cid(&fun.name),
        "lins": fun.lins,
    })
}

fn production_to_json(prod: &Production) -> JsonValue {
    match prod {
        Production::Apply { fid, args } => json!({
            "type": "Apply",
            "fid": fid,
            "args": args.iter().map(p_arg_to_json).collect::<Vec<_>>(),
        }),
        Production::Coerce { arg } => json!({
            "type": "Coerce",
            "arg": arg,
        }),
        Production::Const { cid, expr, tokens } => json!({
            "type": "Const",
            "cid": cid.0,
            "expr": "expr_placeholder",
            "tokens": tokens,
        }),
    }
}

fn p_arg_to_json(arg: &PArg) -> JsonValue {
    json!({
        "type": "PArg",
        "hypos": &arg.hypos,
        "fid": arg.fid,
    })
}

fn sequence_to_json(seq: &[Symbol]) -> JsonValue {
    json!(seq.iter().map(symbol_to_json).collect::<Vec<_>>())
}

fn symbol_to_json(sym: &Symbol) -> JsonValue {
    match sym {
        Symbol::SymCat(n, l) => json!({"type": "SymCat", "args": [n, l]}),
        Symbol::SymLit(n, l) => json!({"type": "SymLit", "args": [n, l]}),
        Symbol::SymVar(n, l) => json!({"type": "SymVar", "args": [n, l]}),
        Symbol::SymKS(t) => json!({"type": "SymKS", "args": [t]}),
        Symbol::SymKP(ts, alts) => json!({"type": "SymKP", "args": [
            ts,
            alts.iter().map(alt_to_json).collect::<Vec<_>>()
        ]}),
        Symbol::SymBind => json!({"type": "SymBind", "args": []}),
        Symbol::SymSoftBind => json!({"type": "SymSoftBind", "args": []}),
        Symbol::SymNE => json!({"type": "SymNE", "args": []}),
        Symbol::SymSoftSpace => json!({"type": "SymSoftSpace", "args": []}),
        Symbol::SymCapital => json!({"type": "SymCapital", "args": []}),
        Symbol::SymAllCapital => json!({"type": "SymAllCapital", "args": []}),
    }
}

fn alt_to_json(alt: &Alt) -> JsonValue {
    json!({
        "type": "Alt",
        "args": [
            alt.tokens,
            alt.prefixes,
        ]
    })
}

fn cat_skeleton(ty: &Type) -> (Vec<CId>, CId) {
    (ty.hypos.iter().map(|h| h.ty.category.clone()).collect(), ty.category.clone())
}

pub fn parse(pgf: &Pgf, lang: &Language, typ: &Type, input: &str) -> Result<Vec<Expr>, PgfError> {
    let tokens = input.split_whitespace().map(|s| s.to_string()).collect::<Vec<_>>();
    let mut state = parse::init_state(pgf, lang, typ)?;

    for token in tokens {
        parse::next_state(&mut state, parse::ParseInput { token })?;
    }

    let (output, _bracketed) = parse::get_parse_output(&state, typ, Some(4));
    match output {
        parse::ParseOutput::ParseOk(trees) => Ok(trees),
        parse::ParseOutput::ParseFail => Err(PgfError::ParseError("Parsing failed".to_string())),
    }
}

pub fn check_expr(pgf: &Pgf, expr: &Expr, expected: &Type) -> Result<(Expr, Type), PgfError> {
    match expr {
        Expr::Fun(cid) => {
            let fun_type = pgf.r#abstract.funs.get(cid)
                .ok_or_else(|| PgfError::TypeCheckError(format!("Unknown function: {}", cid::show_cid(cid))))?
                .ty.clone();
            if fun_type.category == expected.category {
                Ok((expr.clone(), fun_type))
            } else {
                Err(PgfError::TypeCheckError(format!(
                    "Type mismatch: expected {}, got {}",
                    cid::show_cid(&expected.category),
                    cid::show_cid(&fun_type.category)
                )))
            }
        }
        Expr::App(e1, e2) => {
            let (e1_checked, e1_type) = check_expr(pgf, e1, expected)?;
            let (args, result_cat) = cat_skeleton(&e1_type);
            if args.is_empty() || result_cat != expected.category {
                return Err(PgfError::TypeCheckError("Invalid application".to_string()));
            }
            let arg_type = &args[0];
            let (e2_checked, _e2_type) = check_expr(pgf, e2, &Type {
                hypos: vec![],
                category: arg_type.clone(),
                exprs: vec![],
            })?;
            Ok((Expr::App(Box::new(e1_checked), Box::new(e2_checked)), expected.clone()))
        }
        _ => Err(PgfError::TypeCheckError("Unsupported expression for type checking".to_string())),
    }
}

pub fn linearize(pgf: &Pgf, lang: &Language, expr: &Expr) -> Result<String, PgfError> {
    let cnc = pgf.concretes.get(lang).ok_or_else(|| PgfError::UnknownLanguage(cid::show_cid(&lang.0)))?;
    match expr {
        Expr::Fun(cid) => {
            let cnc_fun = cnc.cncfuns.iter().find(|f| f.name == *cid);
            if let Some(fun) = cnc_fun {
                let seq = fun.lins.iter()
                    .filter_map(|&i| cnc.sequences.get(i as usize))
                    .flat_map(|seq| seq.iter().filter_map(|sym| match sym {
                        Symbol::SymKS(s) => Some(s.clone()),
                        Symbol::SymKP(tokens, alts) => Some(tokens.first().cloned().unwrap_or_default()),
                        _ => None,
                    }))
                    .collect::<Vec<_>>();
                Ok(seq.join(" "))
            } else {
                Err(PgfError::ParseError("Function not found in concrete syntax".to_string()))
            }
        }
        Expr::App(e1, e2) => {
            let s1 = linearize(pgf, lang, e1)?;
            let s2 = linearize(pgf, lang, e2)?;
            Ok(format!("{} {}", s1, s2))
        }
        _ => Err(PgfError::ParseError("Unsupported expression for linearization".to_string())),
    }
}

pub fn categories(pgf: &Pgf) -> Vec<CId> {
    pgf.r#abstract.cats.keys().cloned().collect()
}

pub fn category_context(pgf: &Pgf, cat: &CId) -> Option<Vec<Hypo>> {
    pgf.r#abstract.cats.get(cat).map(|c| c.hypos.clone())
}

pub fn functions(pgf: &Pgf) -> Vec<CId> {
    pgf.r#abstract.funs.keys().cloned().collect()
}

pub fn functions_by_cat(pgf: &Pgf, cat: &CId) -> Vec<CId> {
    pgf.r#abstract
        .cats
        .get(cat)
        .map(|c| c.funs.iter().map(|(_, cid)| cid.clone()).collect())
        .unwrap_or_default()
}

pub fn function_type(pgf: &Pgf, fun: &CId) -> Option<Type> {
    pgf.r#abstract.funs.get(fun).map(|f| f.ty.clone())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Write;

    #[test]
    fn test_synthetic_pgf_to_json() {
        let pgf = create_test_pgf();
        let json = pgf_to_json(&pgf).expect("Failed to convert PGF to JSON");
        let mut file = File::create("foods.json").expect("Failed to create output file");
        file.write_all(json.as_bytes()).expect("Failed to write JSON");
        let json_value: serde_json::Value = serde_json::from_str(&json).expect("Invalid JSON");
        assert!(json_value.get("abstract").is_some(), "JSON missing 'abstract' field");
        assert!(json_value.get("concretes").is_some(), "JSON missing 'concretes' field");
    }

    fn create_test_pgf() -> Pgf {
        let mut funs = HashMap::new();
        funs.insert(cid::mk_cid("Pred"), Function {
            ty: Type { hypos: vec![], category: cid::mk_cid("Comment"), exprs: vec![] },
            weight: 1,
            equations: None,
            arity: 0,
            is_constructor: true,
            prob: 1.0,
        });
        funs.insert(cid::mk_cid("This"), Function {
            ty: Type { hypos: vec![], category: cid::mk_cid("Item"), exprs: vec![] },
            weight: 1,
            equations: None,
            arity: 0,
            is_constructor: true,
            prob: 1.0,
        });

        let mut cats = HashMap::new();
        cats.insert(cid::mk_cid("Comment"), Category { hypos: vec![], funs: vec![(0, cid::mk_cid("Pred"))] });
        cats.insert(cid::mk_cid("Item"), Category { hypos: vec![], funs: vec![(0, cid::mk_cid("This"))] });

        let abstract_syntax = Abstract { funs, cats };

        let mut concretes = HashMap::new();
        let mut cncfuns = Vec::new();
        cncfuns.push(CncFun { name: cid::mk_cid("Pred"), lins: vec![0] });
        cncfuns.push(CncFun { name: cid::mk_cid("This"), lins: vec![1] });

        let mut sequences = Vec::new();
        sequences.push(vec![Symbol::SymKS("is".to_string())]);
        sequences.push(vec![Symbol::SymKS("this".to_string())]);

        let mut cnccats = HashMap::new();
        cnccats.insert(cid::mk_cid("Comment"), CncCat { name: cid::mk_cid("Comment"), start: 0, end: 1, labels: vec!["C1".to_string()] });
        cnccats.insert(cid::mk_cid("Item"), CncCat { name: cid::mk_cid("Item"), start: 1, end: 2, labels: vec!["I1".to_string()] });

        let concrete = Concrete {
            cflags: HashMap::new(),
            productions: HashMap::new(),
            cncfuns,
            sequences,
            cnccats,
            printnames: vec![],
            lindefs: vec![],
            linrefs: vec![],
            ccats: vec![],
            total_cats: 2,
        };

        concretes.insert(Language(cid::mk_cid("FoodEng")), concrete);

        Pgf {
            absname: cid::mk_cid("Food"),
            concretes,
            r#abstract: abstract_syntax,
            startcat: cid::mk_cid("Comment"),
            flags: HashMap::new(),
        }
    }

    #[test]
    fn test_synthetic_parse_sentence() {
        let pgf = create_test_pgf();
        let lang = language::read_language("FoodEng").expect("Invalid language");
        let typ = types::start_cat(&pgf);
        let mut state = parse::init_state(&pgf, &lang, &typ).expect("Failed to initialize parse state");
        parse::next_state(&mut state, parse::ParseInput { token: "is".to_string() }).expect("Failed to parse token");
        let (output, _bracketed) = parse::get_parse_output(&state, &typ, Some(4));
        match output {
            parse::ParseOutput::ParseOk(_) => println!("Parse succeeded"),
            parse::ParseOutput::ParseFail => println!("Parse failed"),
        }
    }

    #[test]
    fn test_invalid_pgf() {
        let invalid_data = Bytes::from(vec![0, 1, 2, 3]);
        let result = parse_pgf(invalid_data);
        assert!(matches!(result, Err(PgfError::DeserializeError { .. })), "Expected deserialization error");
    }

    #[test]
    fn test_real_pgf_parsing() {
        let pgf = read_pgf("./grammars/Hello/Hello.pgf").expect("Failed to read PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert to JSON");
        let mut file = File::create("hello.json").expect("Failed to create output file");
        file.write_all(json.as_bytes()).expect("Failed to write JSON");
    }

    #[test]
    fn test_ticket_pgf_parsing() {
        let pgf = read_pgf("./grammars/Ticket/Ticket.pgf").expect("Failed to read Ticket PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert Ticket PGF to JSON");
        let mut file = File::create("ticket.json").expect("Failed to create ticket output file");
        file.write_all(json.as_bytes()).expect("Failed to write Ticket JSON");
    }

    #[test]
    fn test_flight_pgf_parsing() {
        let pgf = read_pgf("./grammars/Flight/Flight.pgf").expect("Failed to read Flight PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert Flight PGF to JSON");
        let mut file = File::create("flight.json").expect("Failed to create flight output file");
        file.write_all(json.as_bytes()).expect("Failed to write Flight JSON");
    }

    #[test]
    fn test_letters_pgf_parsing() {
        let pgf = read_pgf("./grammars/Letters/Letters.pgf").expect("Failed to read Letters PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert Letters PGF to JSON");
        let mut file = File::create("letters.json").expect("Failed to create letters output file");
        file.write_all(json.as_bytes()).expect("Failed to write Letters JSON");
    }
    
    #[test]
    fn test_food_pgf_parsing() {
        let pgf = read_pgf("./grammars/Food/Food.pgf").expect("Failed to read Food PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert Food PGF to JSON");
        let mut file = File::create("food.json").expect("Failed to create food output file");
        file.write_all(json.as_bytes()).expect("Failed to write Food JSON");
    }

    #[test]
    fn test_strings_pgf_parsing() {
        let pgf = read_pgf("./grammars/Letters/Strings.pgf").expect("Failed to read Strings PGF file");
        let json = pgf_to_json(&pgf).expect("Failed to convert Strings PGF to JSON");
        let mut file = File::create("strings.json").expect("Failed to create strings output file");
        file.write_all(json.as_bytes()).expect("Failed to write Strings JSON");
    }

    #[test]
    fn test_read_greeting_string() {
        // Test to parse /grammars/Hello/Hello.pgf and verify the string "Greeting" at offset 180:
        let data = std::fs::read("./grammars/Hello/Hello.pgf").expect("Failed to read PGF file");
        let mut cursor = Cursor::new(&data[..]);
        cursor.set_position(180); // Move to offset 180
        let result = read_string(&mut cursor, false).expect("Failed to read string");
        assert_eq!(cid::show_cid(&result), "Greeting");
    }

    #[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_flight_pgf_parsing() {
        let pgf = read_pgf("Flight.pgf").expect("Failed to read Flight PGF file");
        let lang = language::read_language("FlightEng").expect("Invalid language");
        let typ = types::start_cat(&pgf);
        let input = "Do you have flights from London to Paris ?";
        let trees = parse(&pgf, &lang, &typ, input).expect("Parsing failed");
        assert!(!trees.is_empty(), "No parse trees produced");
        
        let linearized = linearize(&pgf, &lang, &trees[0]).expect("Linearization failed");
        assert_eq!(linearized, "Do you have flights from London to Paris ?");
    }

    #[test]
    fn test_flight_temp() {
        let result = read_pgf("./grammars/Flight/Flight.pgf");
        match result {
            Ok(pgf) => println!("Successfully parsed Flight PGF"),
            Err(e) => {
                println!("Flight PGF parsing error: {:?}", e);
                panic!("Failed to read Flight PGF file: {:?}", e);
            }
        }
    }

    #[test]
    fn test_movies_pgf_parsing() {
        let result = read_pgf("./grammars/Movies/Movies.pgf");
        match result {
            Ok(pgf) => println!("Successfully parsed Movies PGF"),
            Err(e) => {
                println!("Movies PGF parsing error: {:?}", e);
                panic!("Failed to read Movies PGF file: {:?}", e);
            }
        }
    }

    #[test]
    fn test_hello_from_gf_core_pgf_parsing() {
        let result = read_pgf("./grammars/HelloFromGF-Core/Hello.pgf");
        match result {
            Ok(pgf) => println!("Successfully parsed HelloFromGF-Core/Hello PGF"),
            Err(e) => {
                println!("HelloFromGF-Core/Hello PGF parsing error: {:?}", e);
                panic!("Failed to read HelloFromGF-Core/Hello PGF file: {:?}", e);
            }
        }
    }
}
}